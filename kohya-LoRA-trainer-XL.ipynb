{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andyflinn/zs4/blob/master/kohya-LoRA-trainer-XL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slgjeYgd6pWp"
      },
      "source": [
        "[![visitor][visitor-badge]][visitor-stats]\n",
        "[![ko-fi][ko-fi-badge]][ko-fi-link]\n",
        "\n",
        "# **Kohya LoRA Trainer XL**\n",
        "A Colab Notebook For SDXL LoRA Training (Fine-tuning Method)\n",
        "\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Kohya%20LoRA%20Trainer%20XL&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Kohya%20LoRA%20Trainer%20XL\n",
        "[ko-fi-badge]: https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat\n",
        "[ko-fi-link]: https://ko-fi.com/linaqruf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MxF9feWshAp"
      },
      "source": [
        "| Notebook Name | Description | Link |\n",
        "| --- | --- | --- |\n",
        "| [Kohya LoRA Trainer XL](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-trainer-XL.ipynb) | LoRA Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-trainer-XL.ipynb) |\n",
        "| [Kohya Trainer XL](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer-XL.ipynb) | Native Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-trainer-XL.ipynb) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "<h4><font color=\"#4a90e2\"><b>NEWS:</b></font> <i>Colab's free-tier users can now train SDXL LoRA using the diffusers format instead of checkpoint as a pretrained model.</i></h4>\n",
        "<hr>"
      ],
      "metadata": {
        "id": "iIbwGFkJ0nTx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# **I. Prepare Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "_u3q60di584x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd316aa6-a0a2-425a-ff03-fb9e5cbbffbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/kohya-trainer'...\n",
            "remote: Enumerating objects: 2441, done.\u001b[K\n",
            "remote: Counting objects: 100% (1108/1108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (352/352), done.\u001b[K\n",
            "remote: Total 2441 (delta 859), reused 912 (delta 755), pack-reused 1333\u001b[K\n",
            "Receiving objects: 100% (2441/2441), 4.23 MiB | 11.38 MiB/s, done.\n",
            "Resolving deltas: 100% (1613/1613), done.\n",
            "Mounted at /content/drive\n",
            "Cloning into '/content/repositories/infinite-image-browsing'...\n",
            "remote: Enumerating objects: 7805, done.\u001b[K\n",
            "remote: Counting objects: 100% (2201/2201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (586/586), done.\u001b[K\n",
            "remote: Total 7805 (delta 1728), reused 1980 (delta 1573), pack-reused 5604\u001b[K\n",
            "Receiving objects: 100% (7805/7805), 16.90 MiB | 12.74 MiB/s, done.\n",
            "Resolving deltas: 100% (5613/5613), done.\n",
            "Cloning into '/content/repositories/discordia-archivum'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 54 (delta 26), reused 21 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (54/54), 16.04 KiB | 8.02 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\n",
            "orbax-checkpoint 0.4.1 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for discord-protos (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2 lz4\n",
            "0 upgraded, 4 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 1,603 kB of archives.\n",
            "After this operation, 5,676 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.2 [45.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1,086 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 lz4 amd64 1.9.3-2build2 [90.0 kB]\n",
            "Fetched 1,603 kB in 0s (3,366 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Selecting previously unselected package lz4.\n",
            "Preparing to unpack .../lz4_1.9.3-2build2_amd64.deb ...\n",
            "Unpacking lz4 (1.9.3-2build2) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Setting up lz4 (1.9.3-2build2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "--2023-10-27 14:18:46--  https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/669786276/620e2e64-be9f-4599-904f-18ee3811e159?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231027%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231027T141847Z&X-Amz-Expires=300&X-Amz-Signature=0a5e3cbbd333fa11f3e3786b414f0689fd1a98826b671626fcb5bd061a036795&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=669786276&response-content-disposition=attachment%3B%20filename%3Dlibtcmalloc_minimal.so.4&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-10-27 14:18:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/669786276/620e2e64-be9f-4599-904f-18ee3811e159?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231027%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231027T141847Z&X-Amz-Expires=300&X-Amz-Signature=0a5e3cbbd333fa11f3e3786b414f0689fd1a98826b671626fcb5bd061a036795&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=669786276&response-content-disposition=attachment%3B%20filename%3Dlibtcmalloc_minimal.so.4&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 373960 (365K) [application/octet-stream]\n",
            "Saving to: ‘/content/libtcmalloc_minimal.so.4’\n",
            "\n",
            "/content/libtcmallo 100%[===================>] 365.20K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-27 14:18:47 (8.06 MB/s) - ‘/content/libtcmalloc_minimal.so.4’ saved [373960/373960]\n",
            "\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.8/495.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.7/624.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.1/247.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for dadaptation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for elfinder-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m383.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title ## **1.1. Install Kohya Trainer**\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "import requests\n",
        "import torch\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root_dir\n",
        "root_dir          = \"/content\"\n",
        "drive_dir         = os.path.join(root_dir, \"drive/MyDrive\")\n",
        "deps_dir          = os.path.join(root_dir, \"deps\")\n",
        "repo_dir          = os.path.join(root_dir, \"kohya-trainer\")\n",
        "training_dir      = os.path.join(root_dir, \"LoRA\")\n",
        "pretrained_model  = os.path.join(root_dir, \"pretrained_model\")\n",
        "vae_dir           = os.path.join(root_dir, \"vae\")\n",
        "lora_dir          = os.path.join(root_dir, \"network_weight\")\n",
        "repositories_dir  = os.path.join(root_dir, \"repositories\")\n",
        "config_dir        = os.path.join(training_dir, \"config\")\n",
        "tools_dir         = os.path.join(repo_dir, \"tools\")\n",
        "finetune_dir      = os.path.join(repo_dir, \"finetune\")\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "for store in [\"root_dir\", \"repo_dir\", \"training_dir\", \"pretrained_model\", \"vae_dir\", \"repositories_dir\", \"accelerate_config\", \"tools_dir\", \"finetune_dir\", \"config_dir\"]:\n",
        "    with capture.capture_output() as cap:\n",
        "        %store {store}\n",
        "        del cap\n",
        "\n",
        "repo_dict = {\n",
        "    \"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\" : \"https://github.com/qaneel/kohya-trainer\",\n",
        "    \"kohya-ss/sd-scripts (original repo, latest update)\"                    : \"https://github.com/kohya-ss/sd-scripts\",\n",
        "}\n",
        "\n",
        "repository        = \"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\" #@param [\"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\", \"kohya-ss/sd-scripts (original repo, latest update)\"] {allow-input: true}\n",
        "repo_url          = repo_dict[repository]\n",
        "branch            = \"main\"  # @param {type: \"string\"}\n",
        "output_to_drive   = True  # @param {type: \"boolean\"}\n",
        "\n",
        "def clone_repo(url, dir, branch):\n",
        "    if not os.path.exists(dir):\n",
        "       !git clone -b {branch} {url} {dir}\n",
        "\n",
        "def mount_drive(dir):\n",
        "    output_dir      = os.path.join(training_dir, \"output\")\n",
        "\n",
        "    if output_to_drive:\n",
        "        if not os.path.exists(drive_dir):\n",
        "            drive.mount(os.path.dirname(drive_dir))\n",
        "        output_dir  = os.path.join(drive_dir, \"kohya-trainer/output\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    global output_dir\n",
        "\n",
        "    output_dir      = mount_drive(drive_dir)\n",
        "\n",
        "    for dir in [training_dir, config_dir, pretrained_model, vae_dir, repositories_dir, output_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "def pastebin_reader(id):\n",
        "    if \"pastebin.com\" in id:\n",
        "        url = id\n",
        "        if 'raw' not in url:\n",
        "                url = url.replace('pastebin.com', 'pastebin.com/raw')\n",
        "    else:\n",
        "        url = \"https://pastebin.com/raw/\" + id\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    lines = response.text.split('\\n')\n",
        "    return lines\n",
        "\n",
        "def install_repository():\n",
        "    global infinite_image_browser_dir, voldy, discordia_archivum_dir\n",
        "\n",
        "    _, voldy = pastebin_reader(\"kq6ZmHFU\")[:2]\n",
        "\n",
        "    infinite_image_browser_url  = f\"https://github.com/zanllp/{voldy}-infinite-image-browsing.git\"\n",
        "    infinite_image_browser_dir  = os.path.join(repositories_dir, f\"infinite-image-browsing\")\n",
        "    infinite_image_browser_deps = os.path.join(infinite_image_browser_dir, \"requirements.txt\")\n",
        "\n",
        "    discordia_archivum_url = \"https://github.com/Linaqruf/discordia-archivum\"\n",
        "    discordia_archivum_dir = os.path.join(repositories_dir, \"discordia-archivum\")\n",
        "    discordia_archivum_deps = os.path.join(discordia_archivum_dir, \"requirements.txt\")\n",
        "\n",
        "    clone_repo(infinite_image_browser_url, infinite_image_browser_dir, \"main\")\n",
        "    clone_repo(discordia_archivum_url, discordia_archivum_dir, \"main\")\n",
        "\n",
        "    !pip install -q --upgrade -r {infinite_image_browser_deps}\n",
        "    !pip install python-dotenv\n",
        "    !pip install -q --upgrade -r {discordia_archivum_deps}\n",
        "\n",
        "def install_dependencies():\n",
        "    requirements_file = os.path.join(repo_dir, \"requirements.txt\")\n",
        "    model_util        = os.path.join(repo_dir, \"library/model_util.py\")\n",
        "    gpu_info          = getoutput('nvidia-smi')\n",
        "    t4_xformers_wheel = \"https://github.com/Linaqruf/colab-xformers/releases/download/0.0.20/xformers-0.0.20+1d635e1.d20230519-cp310-cp310-linux_x86_64.whl\"\n",
        "\n",
        "    !apt install aria2 lz4\n",
        "    !wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "    !pip install -q --upgrade -r {requirements_file}\n",
        "\n",
        "    if '2.0.1+cu118' in torch.__version__:\n",
        "        if 'T4' in gpu_info:\n",
        "            !pip install -q {t4_xformers_wheel}\n",
        "        else:\n",
        "            !pip install -q xformers==0.0.20\n",
        "    else:\n",
        "        !pip install -q torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "        !pip install -q xformers==0.0.19 triton==2.0.0 -U\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "def prepare_environment():\n",
        "    os.environ[\"LD_PRELOAD\"] = \"/content/libtcmalloc_minimal.so.4\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "    clone_repo(repo_url, repo_dir, branch)\n",
        "    os.chdir(repo_dir)\n",
        "    setup_directories()\n",
        "    install_repository()\n",
        "    install_dependencies()\n",
        "    prepare_environment()\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wrYGu-WxFbsq",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102e4ca6-7996-4765-cde5-27d3bd44c95c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diffusers model is loaded : stabilityai/stable-diffusion-xl-base-1.0\n",
            "\n",
            "Starting downloading from https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\n",
            "Download finished: /content/vae/sdxl_vae.safetensors\n",
            "\n",
            "Selected model: stabilityai/stable-diffusion-xl-base-1.0\n",
            "Selected VAE: /content/vae/sdxl_vae.safetensors\n"
          ]
        }
      ],
      "source": [
        "# @title ## **1.2. Download SDXL**\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import glob\n",
        "import gdown\n",
        "import requests\n",
        "import subprocess\n",
        "from IPython.utils import capture\n",
        "from urllib.parse import urlparse, unquote\n",
        "from pathlib import Path\n",
        "from huggingface_hub import HfFileSystem\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown Place your Huggingface token [here](https://huggingface.co/settings/tokens) to download gated models.\n",
        "\n",
        "HUGGINGFACE_TOKEN     = \"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\" #@param {type: \"string\"}\n",
        "LOAD_DIFFUSERS_MODEL  = True #@param {type: \"boolean\"}\n",
        "SDXL_MODEL_URL        = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param [\"gsdf/CounterfeitXL\", \"Linaqruf/animagine-xl\", \"stabilityai/stable-diffusion-xl-base-1.0\", \"PASTE MODEL URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "SDXL_VAE_URL          = \"Original VAE\" # @param [\"None\", \"Original VAE\", \"FP16 VAE\", \"PASTE VAE URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "\n",
        "MODEL_URLS = {\n",
        "    \"gsdf/CounterfeitXL\"        : \"https://huggingface.co/gsdf/CounterfeitXL/resolve/main/CounterfeitXL_%CE%B2.safetensors\",\n",
        "    \"Linaqruf/animagine-xl\"   : \"https://huggingface.co/Linaqruf/animagine-xl/resolve/main/animagine-xl.safetensors\",\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\" : \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\",\n",
        "}\n",
        "VAE_URLS = {\n",
        "    \"None\"                    : \"\",\n",
        "    \"Original VAE\"           : \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\",\n",
        "    \"FP16 VAE\"           : \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae.safetensors\"\n",
        "}\n",
        "\n",
        "SDXL_MODEL_URL = MODEL_URLS.get(SDXL_MODEL_URL, SDXL_MODEL_URL)\n",
        "SDXL_VAE_URL = VAE_URLS.get(SDXL_VAE_URL, SDXL_VAE_URL)\n",
        "\n",
        "def get_filename(url):\n",
        "    if any(url.endswith(ext) for ext in [\".ckpt\", \".safetensors\", \".pt\", \".pth\"]):\n",
        "        return os.path.basename(url)\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    if 'content-disposition' in response.headers:\n",
        "        filename = re.findall('filename=\"?([^\"]+)\"?', response.headers['content-disposition'])[0]\n",
        "    else:\n",
        "        filename = unquote(os.path.basename(urlparse(url).path))\n",
        "\n",
        "    return filename\n",
        "\n",
        "def aria2_download(dir, filename, url):\n",
        "    user_header = f\"Authorization: Bearer {HUGGINGFACE_TOKEN}\"\n",
        "    aria2_args = [\n",
        "        \"aria2c\",\n",
        "        \"--console-log-level=error\",\n",
        "        \"--summary-interval=10\",\n",
        "        f\"--header={user_header}\" if \"huggingface.co\" in url else \"\",\n",
        "        \"--continue=true\",\n",
        "        \"--max-connection-per-server=16\",\n",
        "        \"--min-split-size=1M\",\n",
        "        \"--split=16\",\n",
        "        f\"--dir={dir}\",\n",
        "        f\"--out={filename}\",\n",
        "        url\n",
        "    ]\n",
        "    subprocess.run(aria2_args)\n",
        "\n",
        "def download(url, dst):\n",
        "    print(f\"Starting downloading from {url}\")\n",
        "    filename = get_filename(url)\n",
        "    filepath = os.path.join(dst, filename)\n",
        "\n",
        "    if \"drive.google.com\" in url:\n",
        "        gdown.download(url, filepath, quiet=False)\n",
        "    else:\n",
        "        if \"huggingface.co\" in url and \"/blob/\" in url:\n",
        "            url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "        aria2_download(dst, filename, url)\n",
        "\n",
        "    print(f\"Download finished: {filepath}\")\n",
        "    return filepath\n",
        "\n",
        "def all_folders_present(base_model_url, sub_folders):\n",
        "    fs = HfFileSystem()\n",
        "    existing_folders = set(fs.ls(base_model_url, detail=False))\n",
        "\n",
        "    for folder in sub_folders:\n",
        "        full_folder_path = f\"{base_model_url}/{folder}\"\n",
        "        if full_folder_path not in existing_folders:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def get_total_ram_gb():\n",
        "    with open('/proc/meminfo', 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            if \"MemTotal\" in line:\n",
        "                return int(line.split()[1]) / (1024**2)  # Convert to GB\n",
        "\n",
        "def get_gpu_name():\n",
        "    try:\n",
        "        return subprocess.check_output(\"nvidia-smi --query-gpu=name --format=csv,noheader,nounits\", shell=True).decode('ascii').strip()\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    global model_path, vae_path, LOAD_DIFFUSERS_MODEL\n",
        "\n",
        "    model_path, vae_path = None, None\n",
        "\n",
        "    required_sub_folders = [\n",
        "        'scheduler',\n",
        "        'text_encoder',\n",
        "        'text_encoder_2',\n",
        "        'tokenizer',\n",
        "        'tokenizer_2',\n",
        "        'unet',\n",
        "        'vae',\n",
        "    ]\n",
        "\n",
        "    download_targets = {\n",
        "        \"model\": (SDXL_MODEL_URL, pretrained_model),\n",
        "        \"vae\": (SDXL_VAE_URL, vae_dir),\n",
        "    }\n",
        "\n",
        "    total_ram = get_total_ram_gb()\n",
        "    gpu_name = get_gpu_name()\n",
        "\n",
        "    # Check hardware constraints\n",
        "    if total_ram < 13 and gpu_name in [\"Tesla T4\", \"Tesla V100\"]:\n",
        "        print(\"Attempt to load diffusers model instead due to hardware constraints.\")\n",
        "        if not LOAD_DIFFUSERS_MODEL:\n",
        "            LOAD_DIFFUSERS_MODEL = True\n",
        "\n",
        "    for target, (url, dst) in download_targets.items():\n",
        "        if url and not url.startswith(f\"PASTE {target.upper()} URL OR GDRIVE PATH HERE\"):\n",
        "            if target == \"model\" and LOAD_DIFFUSERS_MODEL:\n",
        "                # Code for checking and handling diffusers model\n",
        "                if 'huggingface.co' in url:\n",
        "                    match = re.search(r'huggingface\\.co/([^/]+)/([^/]+)', SDXL_MODEL_URL)\n",
        "                    if match:\n",
        "                        username = match.group(1)\n",
        "                        model_name = match.group(2)\n",
        "                        url = f\"{username}/{model_name}\"\n",
        "                if all_folders_present(url, required_sub_folders):\n",
        "                    print(f\"Diffusers model is loaded : {url}\")\n",
        "                    model_path = url\n",
        "                else:\n",
        "                    print(\"Repository doesn't exist or no diffusers model detected.\")\n",
        "                    filepath = download(url, dst)  # Continue with the regular download\n",
        "                    model_path = filepath\n",
        "            else:\n",
        "                filepath = download(url, dst)\n",
        "\n",
        "                if target == \"model\":\n",
        "                    model_path = filepath\n",
        "                elif target == \"vae\":\n",
        "                    vae_path = filepath\n",
        "\n",
        "            print()\n",
        "\n",
        "    if model_path:\n",
        "        print(f\"Selected model: {model_path}\")\n",
        "\n",
        "    if vae_path:\n",
        "        print(f\"Selected VAE: {vae_path}\")\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "kh7CeDqK4l3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3e56c7-310b-4072-8770-893bcb64da63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'train_data_dir' (str)\n",
            "Your train data directory : /content/drive/MyDrive/Loras/andyflinn\n"
          ]
        }
      ],
      "source": [
        "# @title ## **1.3. Directory Config**\n",
        "# @markdown Specify the location of your training data in the following cell. A folder with the same name as your input will be created.\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "train_data_dir = \"/content/drive/MyDrive/Loras/andyflinn\"  # @param {'type' : 'string'}\n",
        "%store train_data_dir\n",
        "\n",
        "os.makedirs(train_data_dir, exist_ok=True)\n",
        "print(f\"Your train data directory : {train_data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qqUYtRn0RPoK"
      },
      "outputs": [],
      "source": [
        "# @title ## **1.4. Image Browser**\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import portpicker\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from threading import Thread\n",
        "from imjoy_elfinder.app import main\n",
        "from google.colab.output import serve_kernel_port_as_iframe, serve_kernel_port_as_window\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown This cell allows you to view and manage your images in real-time. You can use it to:\n",
        "# @markdown - Prepare your dataset before training\n",
        "# @markdown - Monitor the sample outputs during training.\n",
        "\n",
        "root_dir      = \"/content\"\n",
        "browser_type  = \"imjoy-elfinder\" #@param [\"imjoy-elfinder\", \"infinite-image-browsing\"]\n",
        "window_height = 550 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "\n",
        "main_app          = os.path.join(infinite_image_browser_dir, \"app.py\")\n",
        "config_file       = os.path.join(infinite_image_browser_dir, \"config.json\")\n",
        "port              = portpicker.pick_unused_port()\n",
        "\n",
        "config = {\n",
        "    \"outdir_txt2img_samples\": train_data_dir,\n",
        "}\n",
        "\n",
        "def write_file(filename, config):\n",
        "    with open(filename, 'w',) as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "def run_app():\n",
        "    !python {main_app} --port={port} --sd_webui_config={config_file} > /dev/null 2>&1\n",
        "\n",
        "def launch():\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "    thread = Thread(target=main, args=[[f\"--root-dir={root_dir}\",\n",
        "                                        f\"--port={port}\",\n",
        "                                        f\"--thumbnail\"]])\n",
        "\n",
        "    if browser_type == \"infinite-image-browsing\":\n",
        "        os.chdir(train_data_dir)\n",
        "        write_file(config_file, config)\n",
        "\n",
        "        thread = Thread(target=run_app)\n",
        "\n",
        "    thread.start()\n",
        "\n",
        "    serve_kernel_port_as_iframe(port, width='100%', height=window_height, cache_in_notebook=False)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9UUwGNMRMM"
      },
      "source": [
        "# **II. Data Gathering**\n",
        "\n",
        "You have three options for collecting your dataset:\n",
        "\n",
        "1. Upload it to Colab's local files.\n",
        "2. Use the `Simple Booru Scraper` to download images in bulk from Danbooru.\n",
        "3. Locate your dataset in Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t17ZfiMB8GWZ"
      },
      "outputs": [],
      "source": [
        "# @title ## **2.1. Unzip Dataset**\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import re\n",
        "from urllib.parse import unquote\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# @title ## Unzip Dataset\n",
        "# @markdown If your dataset is in a `zip` file and has been uploaded to a location, use this section to extract it.\n",
        "# @markdown The dataset will be downloaded and automatically extracted to `train_data_dir` if `unzip_to` is empty.\n",
        "\n",
        "zipfile_url = \"\"  # @param {type:\"string\"}\n",
        "unzip_to = \"\"  # @param {type:\"string\"}\n",
        "hf_token = \"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\"\n",
        "\n",
        "use_aria2c = True # @param {type:\"boolean\"}\n",
        "preserve_folders = True # @param {type:\"boolean\"}\n",
        "remove_after_unzipping = False # @param {type:\"boolean\"}\n",
        "\n",
        "if \"huggingface.co\" in zipfile_url and \"blob\" in zipfile_url:\n",
        "    zipfile_url = zipfile_url.replace(\"blob\", \"resolve\")\n",
        "\n",
        "if not unzip_to:\n",
        "    unzip_to = train_data_dir\n",
        "\n",
        "def get_filename_from_url(url):\n",
        "    if \"huggingface.co\" or \"/content/\" in url:\n",
        "        return os.path.basename(url)\n",
        "\n",
        "    response = requests.head(url, allow_redirects=True)\n",
        "    cd = response.headers.get('content-disposition')\n",
        "    if cd:\n",
        "        fname = re.findall('filename=(.+)', cd)\n",
        "        if len(fname) == 0:\n",
        "            return \"zipfile.zip\"\n",
        "        return unquote(fname[0])\n",
        "\n",
        "    return \"zipfile.zip\"\n",
        "\n",
        "def download_with_requests(url, output_path):\n",
        "    print(f\"Downloading {url} with requests...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(output_path, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "    print(f\"Downloaded to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def download_with_aria2c(url, output_path):\n",
        "    print(f\"Downloading {url} with aria2c...\")\n",
        "    aria_args = {\n",
        "        'console-log-level': 'error',\n",
        "        'summary-interval': '10',\n",
        "        'continue': 'true',\n",
        "        'max-connection-per-server': '16',\n",
        "        'min-split-size': '1M',\n",
        "        'split': '16',\n",
        "        'dir': os.path.dirname(output_path),\n",
        "        'out': os.path.basename(output_path),\n",
        "    }\n",
        "\n",
        "    if \"huggingface.co\" in url:\n",
        "        aria_args['header'] = f\"Authorization: Bearer {hf_token}\"\n",
        "\n",
        "    cmd = ['aria2c'] + [f'--{k}={v}' for k, v in aria_args.items()] + [url]\n",
        "    subprocess.run(cmd)\n",
        "    print(f\"Downloaded to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def move_files(train_dir):\n",
        "    for filename in os.listdir(train_dir):\n",
        "        file_path = os.path.join(train_dir, filename)\n",
        "        if filename.startswith(\"meta_\") and filename.endswith(\".json\"):\n",
        "            if not os.path.exists(file_path):\n",
        "                shutil.move(file_path, training_dir)\n",
        "            else:\n",
        "                os.remove(file_path)\n",
        "\n",
        "def remove_empty_dirs(path):\n",
        "    for dirpath, dirnames, files in os.walk(path, topdown=False):  # start from leaf folders\n",
        "        for dirname in dirnames:\n",
        "            full_dir_path = os.path.join(dirpath, dirname)\n",
        "            if not os.listdir(full_dir_path):  # Check if directory is empty\n",
        "                os.rmdir(full_dir_path)\n",
        "                print(f\"Removed empty directory: {full_dir_path}\")\n",
        "\n",
        "def extract_dataset(zip_file, output_path):\n",
        "    with ZipFile(zip_file, 'r') as zip_ref:\n",
        "        print(f\"Extracting {zip_file} to {output_path}...\")\n",
        "\n",
        "        if not preserve_folders:  # If we do not want to preserve folder structure\n",
        "            for member in zip_ref.namelist():\n",
        "                # Extract only the file name, discard directory structure\n",
        "                filename = os.path.basename(member)\n",
        "                if filename:  # Check if file name is not empty (this skips directories)\n",
        "                    zip_ref.extract(member, output_path)\n",
        "                    source_path = os.path.join(output_path, member)\n",
        "                    target_path = os.path.join(output_path, filename)\n",
        "                    os.rename(source_path, target_path)\n",
        "\n",
        "            remove_empty_dirs(output_path)\n",
        "\n",
        "        else:\n",
        "            zip_ref.extractall(output_path)\n",
        "\n",
        "        print(\"Extraction completed!\")\n",
        "\n",
        "def download_dataset(url, output_path):\n",
        "    if url.startswith(\"/content\"):\n",
        "        print(f\"Using file at {url}\")\n",
        "        return url\n",
        "\n",
        "    elif \"drive.google.com\" in url:\n",
        "        print(\"Downloading from Google Drive...\")\n",
        "        cmd = ['gdown', '--id', url.split('/')[-2], '-O', output_path]\n",
        "        subprocess.run(cmd)\n",
        "        return output_path\n",
        "\n",
        "    elif use_aria2c:\n",
        "        return download_with_aria2c(url, output_path)\n",
        "\n",
        "    else:\n",
        "        return download_with_requests(url, output_path)\n",
        "\n",
        "def main():\n",
        "    zipfile_name = get_filename_from_url(zipfile_url)\n",
        "    output_path = os.path.join(root_dir, zipfile_name)\n",
        "\n",
        "    zip_file = download_dataset(zipfile_url, output_path)\n",
        "\n",
        "    extract_dataset(zip_file, unzip_to)\n",
        "\n",
        "    move_files(unzip_to)\n",
        "\n",
        "    if remove_after_unzipping and \"/content/drive\" not in zip_file:\n",
        "        os.remove(zip_file)\n",
        "        print(f\"Removed {zip_file}\")\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A0t1dfnU5Xkq"
      },
      "outputs": [],
      "source": [
        "#@title ## **2.2. Imageboard Scraper**\n",
        "import os\n",
        "import html\n",
        "from IPython.utils import capture\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "#@markdown Use `gallery-dl` to scrape images from an imageboard site. To specify `prompt(s)`, separate them with commas (e.g., `hito_komoru, touhou`).\n",
        "booru = \"Danbooru\" #@param [\"Danbooru\", \"Gelbooru\", \"Safebooru\"]\n",
        "prompt = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Alternatively, you can provide a `custom_url` instead of using a predefined site.\n",
        "custom_url = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Use the `sub_folder` option to organize the downloaded images into separate folders based on their concept or category.\n",
        "sub_folder = \"\" #@param {type: \"string\"}\n",
        "\n",
        "user_agent = \"gdl/1.24.5\"\n",
        "\n",
        "#@markdown You can limit the number of images to download by using the `--range` option followed by the desired range (e.g., `1-200`).\n",
        "range = \"\" #@param {type: \"string\"}\n",
        "\n",
        "write_tags = False #@param {type: \"boolean\"}\n",
        "\n",
        "additional_arguments = \"--filename /O --no-part\"\n",
        "\n",
        "tags = prompt.split(',')\n",
        "tags = '+'.join(tags)\n",
        "\n",
        "replacement_dict = {\" \": \"\", \"(\": \"%28\", \")\": \"%29\", \":\": \"%3a\"}\n",
        "tags = ''.join(replacement_dict.get(c, c) for c in tags)\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "if booru == \"Danbooru\":\n",
        "    url = \"https://danbooru.donmai.us/posts?tags={}\".format(tags)\n",
        "elif booru == \"Gelbooru\":\n",
        "    url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "else:\n",
        "    url = \"https://safebooru.org/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "\n",
        "valid_url = custom_url if custom_url else url\n",
        "\n",
        "def scrape(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "def pre_process_tags(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        item_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(item_path) and item.endswith(\".txt\"):\n",
        "            old_path = item_path\n",
        "            new_file_name = os.path.splitext(os.path.splitext(item)[0])[0] + \".txt\"\n",
        "            new_path = os.path.join(directory, new_file_name)\n",
        "\n",
        "            os.rename(old_path, new_path)\n",
        "\n",
        "            with open(new_path, \"r\") as f:\n",
        "                contents = f.read()\n",
        "\n",
        "            contents = html.unescape(contents)\n",
        "            contents = contents.replace(\"_\", \" \")\n",
        "            contents = \", \".join(contents.split(\"\\n\"))\n",
        "\n",
        "            with open(new_path, \"w\") as f:\n",
        "                f.write(contents)\n",
        "\n",
        "        elif os.path.isdir(item_path):\n",
        "            pre_process_tags(item_path)\n",
        "\n",
        "get_url_config = {\n",
        "    \"_valid_url\" : valid_url,\n",
        "    \"get-urls\" : True,\n",
        "    \"range\" : range if range else None,\n",
        "    \"user-agent\" : user_agent\n",
        "}\n",
        "\n",
        "scrape_config = {\n",
        "    \"_valid_url\" : valid_url,\n",
        "    \"directory\" : image_dir,\n",
        "    \"write-tags\" : write_tags,\n",
        "    \"range\" : range if range else None,\n",
        "    \"user-agent\" : user_agent\n",
        "}\n",
        "\n",
        "get_url_args = scrape(get_url_config)\n",
        "scrape_args = scrape(scrape_config)\n",
        "scraper_text = os.path.join(root_dir, \"scrape_this.txt\")\n",
        "\n",
        "if write_tags:\n",
        "    !gallery-dl {scrape_args} {additional_arguments}\n",
        "    pre_process_tags(train_data_dir)\n",
        "else:\n",
        "    with capture.capture_output() as cap:\n",
        "        !gallery-dl {get_url_args} {additional_arguments}\n",
        "    with open(scraper_text, \"w\") as f:\n",
        "        f.write(cap.stdout)\n",
        "\n",
        "    os.chdir(image_dir)\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -i {scraper_text}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EVWk3PM2KKB7"
      },
      "outputs": [],
      "source": [
        "#@title ## **2.3. Journey Scraper**\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "# @markdown Enter your Discord token below.\n",
        "token = \"\" #@param {type: \"string\"}\n",
        "channel_id = \"1022054094476673085\" #@param {type: \"string\"}\n",
        "# @markdown Which bot do you want to scrape? This code is optimized to only scrape non-grid images from the Journey bot, so don't worry about cropping.\n",
        "bot = \"niji\" #@param [\"niji\", \"mid\"]\n",
        "# @markdown Set the limit of messages to scrape here. (This does not limit the number of messages to download.)\n",
        "limit = 10000 #@param {type: \"number\"}\n",
        "# @markdown To specify the `include_word` and `undesired_word`, separate them with commas (e.g., hito_komoru, touhou). By default, it scrapes the newest Niji model.\n",
        "include_word = \"girl\" #@param {type:\"string\"}\n",
        "undesired_word = \"--style, --niji 4\" #@param {type:\"string\"}\n",
        "download_attachments = \"single\"\n",
        "\n",
        "def scrape(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "scrape_config = {\n",
        "    \"token\": token,\n",
        "    \"channel_id\": channel_id,\n",
        "    \"nijijourney\": True if bot == \"niji\" else False,\n",
        "    \"midjourney\": True if bot == \"mid\" else False,\n",
        "    \"limit\": limit if limit else None,\n",
        "    \"prompt\": include_word,\n",
        "    \"single\": True,\n",
        "    \"undesired_word\": undesired_word,\n",
        "    \"download_attachments\": True,\n",
        "    \"output_folder\": train_data_dir,\n",
        "\n",
        "}\n",
        "\n",
        "scrape_args = scrape(scrape_config)\n",
        "\n",
        "os.chdir(discordia_archivum_dir)\n",
        "!python main.py {scrape_args}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-0qKyEgTchp"
      },
      "source": [
        "# **III. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "Jz2emq6vWnPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b479ab-7fc8-42bb-c222-1376d41060df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 4733.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All images have been converted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# @title ## **3.1. Data Cleaning**\n",
        "import os\n",
        "import random\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "#@markdown This section removes unsupported media types such as `.mp4`, `.webm`, and `.gif`, as well as any unnecessary files.\n",
        "#@markdown To convert a transparent dataset with an alpha channel (RGBA) to RGB and give it a white background, set the `convert` parameter to `True`.\n",
        "convert = True  # @param {type:\"boolean\"}\n",
        "#@markdown Alternatively, you can give the background a `random_color` instead of white by checking the corresponding option.\n",
        "random_color = True  # @param {type:\"boolean\"}\n",
        "recursive = False\n",
        "\n",
        "batch_size = 32\n",
        "supported_types = [\n",
        "    \".png\",\n",
        "    \".jpg\",\n",
        "    \".jpeg\",\n",
        "    \".webp\",\n",
        "    \".bmp\",\n",
        "    \".caption\",\n",
        "    \".npz\",\n",
        "    \".txt\",\n",
        "    \".json\",\n",
        "]\n",
        "\n",
        "background_colors = [\n",
        "    (255, 255, 255),\n",
        "    (0, 0, 0),\n",
        "    (255, 0, 0),\n",
        "    (0, 255, 0),\n",
        "    (0, 0, 255),\n",
        "    (255, 255, 0),\n",
        "    (255, 0, 255),\n",
        "    (0, 255, 255),\n",
        "]\n",
        "\n",
        "def clean_directory(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(file_path):\n",
        "            file_ext = os.path.splitext(item)[1]\n",
        "            if file_ext not in supported_types:\n",
        "                print(f\"Deleting file {item} from {directory}\")\n",
        "                os.remove(file_path)\n",
        "        elif os.path.isdir(file_path) and recursive:\n",
        "            clean_directory(file_path)\n",
        "\n",
        "def process_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img_dir, image_name = os.path.split(image_path)\n",
        "\n",
        "    if img.mode in (\"RGBA\", \"LA\"):\n",
        "        if random_color:\n",
        "            background_color = random.choice(background_colors)\n",
        "        else:\n",
        "            background_color = (255, 255, 255)\n",
        "        bg = Image.new(\"RGB\", img.size, background_color)\n",
        "        bg.paste(img, mask=img.split()[-1])\n",
        "\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            bg = bg.convert(\"RGB\")\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            bg.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            bg.save(image_path, \"PNG\")\n",
        "            print(f\" Converted image: {image_name}\")\n",
        "    else:\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            img.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            img.save(image_path, \"PNG\")\n",
        "\n",
        "def find_images(directory):\n",
        "    images = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".png\") or file.endswith(\".webp\"):\n",
        "                images.append(os.path.join(root, file))\n",
        "    return images\n",
        "\n",
        "clean_directory(train_data_dir)\n",
        "images = find_images(train_data_dir)\n",
        "num_batches = len(images) // batch_size + 1\n",
        "\n",
        "if convert:\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        for i in tqdm(range(num_batches)):\n",
        "            start = i * batch_size\n",
        "            end = start + batch_size\n",
        "            batch = images[start:end]\n",
        "            executor.map(process_image, batch)\n",
        "\n",
        "    print(\"All images have been converted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdISafLeyklg"
      },
      "source": [
        "## **3.2. Data Captioning**\n",
        "\n",
        "- For general images, use BLIP captioning.\n",
        "- For anime and manga-style images, use Waifu Diffusion 1.4 Tagger V2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "nvPyH-G_Qdha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c07ad8-4c02-4c08-c012-6346eeb98a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load images from /content/drive/MyDrive/Loras/andyflinn\n",
            "found 120 images.\n",
            "loading BLIP caption: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 5.21MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 100kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 2.19MB/s]\n",
            "100% 1.66G/1.66G [00:19<00:00, 92.3MB/s]\n",
            "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "BLIP loaded\n",
            "  0% 0/15 [00:00<?, ?it/s]/content/drive/MyDrive/Loras/andyflinn/dataset/001.jpg a man with a hat and glasses playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/002.jpg a man in a hat playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/003.jpg a man with glasses playing a guitar and singing\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/004.jpg a man with glasses is speaking into a microphone\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/005.jpg a man with a hat on smiling at the camera\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/006.jpg a man with a hat on looking off to the side\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/007.jpg a man with a hat and glasses singing into a microphone\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/008.jpg a man in a hat and glasses yelling\n",
            "  7% 1/15 [02:18<32:13, 138.13s/it]/content/drive/MyDrive/Loras/andyflinn/dataset/009.jpg a man standing in front of a microphone\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/010.jpg a man in a hat and glasses holding a cell phone\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/011.jpg a man with a hat and glasses playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/012.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/013.jpg a man with glasses and a hat is smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/014.jpg a man with a hat and glasses looking at a bird\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/015.jpg a man with a hat and glasses standing in front of a lake\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/016.jpg a man with a hat and glasses standing in front of a castle\n",
            " 13% 2/15 [04:36<29:59, 138.41s/it]/content/drive/MyDrive/Loras/andyflinn/dataset/017.jpg a man with a hat and glasses standing in front of a painting\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/018.jpg a man wearing a hat and glasses in front of a building\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/019.jpg a man wearing a hat and glasses standing in front of a building\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/020.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/021.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/022.jpg a man wearing a hat and glasses standing in front of a lake\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/023.jpg a man wearing a hat and glasses in a city\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/024.jpg a man with a hat and glasses smiling\n",
            " 20% 3/15 [07:04<28:19, 141.63s/it]/content/drive/MyDrive/Loras/andyflinn/dataset/025.jpg a man with glasses and a green shirt is smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/026.jpg a man sitting at a table with a glass of beer\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/027.jpg a man in a hat holding a pie\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/028.jpg a man with a hat and a jacket smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/029.jpg a man with a hat on smiling at the camera\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/030.jpg a man with a hat and glasses holding a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/031.jpg a man with a hat and glasses is playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/032.jpg a man with glasses and a hat smiles\n",
            " 27% 4/15 [09:12<25:19, 138.11s/it]/content/drive/MyDrive/Loras/andyflinn/dataset/033.jpg a man wearing a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/034.jpg a man in a hat and glasses standing by a river\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/035.jpg a man in a yellow shirt and glasses standing in front of a wall of sliced cucumbers\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/036.jpg a man with glasses and a hat on\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/037.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/038.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/039.jpg a man wearing a hat and glasses in front of a wall\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/040.jpg a man in a hat and glasses is smiling\n",
            " 33% 5/15 [12:02<24:05, 144.52s/it]/content/drive/MyDrive/Loras/andyflinn/dataset/041.jpg a man with a guitar case on his back\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/042.jpg a man with a hat playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/043.jpg a man with a hat playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/044.jpg a man with a hat playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/045.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/046.jpg a man in a hat and glasses playing a drum\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/047.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/048.jpg a man with a hat and glasses smiling\n",
            " 40% 6/15 [14:07<21:10, 141.18s/it]/content/drive/MyDrive/Loras/andyflinn/dataset/049.jpg a man with glasses and a hat on\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/050.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/051.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/052.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/053.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/054.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/055.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/056.jpg a man with a hat and glasses smiling\n",
            " 47% 7/15 [16:05<18:22, 137.87s/it]/content/drive/MyDrive/Loras/andyflinn/dataset/057.jpg a man in a hat and glasses standing in a city\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/058.jpg a man with glasses smiling in front of a bridge\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/059.jpg a man with glasses and a hat standing in front of a building\n",
            "/content/drive/MyDrive/Loras/andyflinn/dataset/060.jpg a man with glasses and a suit smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/001.jpg a man with a hat and glasses playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/002.jpg a man in a hat playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/003.jpg a man with glasses playing a guitar and singing\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/004.jpg a man with glasses is speaking into a microphone\n",
            " 53% 8/15 [18:30<16:11, 138.82s/it]/content/drive/MyDrive/Loras/andyflinn/images/005.jpg a man with a hat on smiling at the camera\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/006.jpg a man with a hat on looking off to the side\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/007.jpg a man with a hat and glasses singing into a microphone\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/008.jpg a man in a hat and glasses yelling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/009.jpg a man standing in front of a microphone\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/010.jpg a man in a hat and glasses holding a cell phone\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/011.jpg a man with a hat and glasses playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/012.jpg a man with a hat and glasses smiling\n",
            " 60% 9/15 [20:40<13:47, 137.84s/it]/content/drive/MyDrive/Loras/andyflinn/images/013.jpg a man with glasses and a hat is smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/014.jpg a man with a hat and glasses looking at a bird\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/015.jpg a man with a hat and glasses standing in front of a lake\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/016.jpg a man with a hat and glasses standing in front of a castle\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/017.jpg a man with a hat and glasses standing in front of a painting\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/018.jpg a man wearing a hat and glasses in front of a building\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/019.jpg a man wearing a hat and glasses standing in front of a building\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/020.jpg a man with glasses and a hat smiling\n",
            " 67% 10/15 [23:02<11:31, 138.27s/it]/content/drive/MyDrive/Loras/andyflinn/images/021.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/022.jpg a man wearing a hat and glasses standing in front of a lake\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/023.jpg a man wearing a hat and glasses in a city\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/024.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/025.jpg a man with glasses and a green shirt is smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/026.jpg a man sitting at a table with a glass of beer\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/027.jpg a man in a hat holding a pie\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/028.jpg a man with a hat and a jacket smiling\n",
            " 73% 11/15 [25:20<09:12, 138.19s/it]/content/drive/MyDrive/Loras/andyflinn/images/029.jpg a man with a hat on smiling at the camera\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/030.jpg a man with a hat and glasses holding a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/031.jpg a man with a hat and glasses is playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/032.jpg a man with glasses and a hat smiles\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/033.jpg a man wearing a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/034.jpg a man in a hat and glasses standing by a river\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/035.jpg a man in a yellow shirt and glasses standing in front of a wall of sliced cucumbers\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/036.jpg a man with glasses and a hat on\n",
            " 80% 12/15 [28:14<07:03, 141.24s/it]/content/drive/MyDrive/Loras/andyflinn/images/037.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/038.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/039.jpg a man wearing a hat and glasses in front of a wall\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/040.jpg a man in a hat and glasses is smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/041.jpg a man with a guitar case on his back\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/042.jpg a man with a hat playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/043.jpg a man with a hat playing a guitar\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/044.jpg a man with a hat playing a guitar\n",
            " 87% 13/15 [30:31<04:41, 140.86s/it]/content/drive/MyDrive/Loras/andyflinn/images/045.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/046.jpg a man in a hat and glasses playing a drum\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/047.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/048.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/049.jpg a man with glasses and a hat on\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/050.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/051.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/052.jpg a man with a hat and glasses smiling\n",
            " 93% 14/15 [32:34<02:19, 139.60s/it]/content/drive/MyDrive/Loras/andyflinn/images/053.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/054.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/055.jpg a man with glasses and a hat smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/056.jpg a man with a hat and glasses smiling\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/057.jpg a man in a hat and glasses standing in a city\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/058.jpg a man with glasses smiling in front of a bridge\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/059.jpg a man with glasses and a hat standing in front of a building\n",
            "/content/drive/MyDrive/Loras/andyflinn/images/060.jpg a man with glasses and a suit smiling\n",
            "100% 15/15 [34:53<00:00, 139.57s/it]\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "#@title ### **3.2.1. BLIP Captioning**\n",
        "#@markdown BLIP is a pre-training framework for unified vision-language understanding and generation, which achieves state-of-the-art results on a wide range of vision-language tasks. It can be used as a tool for image captioning, for example, `astronaut riding a horse in space`.\n",
        "import os\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "beam_search = True #@param {type:'boolean'}\n",
        "min_length = 5 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "max_length = 75 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"   : train_data_dir,\n",
        "    \"batch_size\"        : 8,\n",
        "    \"beam_search\"       : beam_search,\n",
        "    \"min_length\"        : min_length,\n",
        "    \"max_length\"        : max_length,\n",
        "    \"debug\"             : True,\n",
        "    \"caption_extension\" : \".caption\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"recursive\"         : True\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python make_captions.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-BdXV7rAy2ag"
      },
      "outputs": [],
      "source": [
        "#@title ### **3.2.2. Waifu Diffusion 1.4 Tagger V2**\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "#@markdown [Waifu Diffusion 1.4 Tagger V2](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags) is a Danbooru-styled image classification model developed by SmilingWolf. It can also be useful for general image tagging, for example, `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background`.\n",
        "model = \"SmilingWolf/wd-v1-4-moat-tagger-v2\" #@param [\"SmilingWolf/wd-v1-4-moat-tagger-v2\", \"SmilingWolf/wd-v1-4-convnextv2-tagger-v2\", \"SmilingWolf/wd-v1-4-swinv2-tagger-v2\", \"SmilingWolf/wd-v1-4-convnext-tagger-v2\", \"SmilingWolf/wd-v1-4-vit-tagger-v2\"]\n",
        "#@markdown Separate `undesired_tags` with comma `(,)` if you want to remove multiple tags, e.g. `1girl,solo,smile`.\n",
        "undesired_tags = \"\" #@param {type:'string'}\n",
        "#@markdown Adjust `general_threshold` for pruning tags (less tags, less flexible). `character_threshold` is useful if you want to train with character tags, e.g. `hakurei reimu`.\n",
        "general_threshold = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "character_threshold = 0.85 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"           : train_data_dir,\n",
        "    \"batch_size\"                : 8,\n",
        "    \"repo_id\"                   : model,\n",
        "    \"recursive\"                 : True,\n",
        "    \"remove_underscore\"         : True,\n",
        "    \"general_threshold\"         : general_threshold,\n",
        "    \"character_threshold\"       : character_threshold,\n",
        "    \"caption_extension\"         : \".txt\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"debug\"                     : True,\n",
        "    \"undesired_tags\"            : undesired_tags\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python tag_images_by_wd14_tagger.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "_mLVURhM9PFE"
      },
      "outputs": [],
      "source": [
        "# @title ### **3.2.3. Custom Caption/Tag**\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown Add or remove custom tags here.\n",
        "extension   = \".txt\"  # @param [\".txt\", \".caption\"]\n",
        "custom_tag  = \"andyflinn\"  # @param {type:\"string\"}\n",
        "# @markdown Use `sub_folder` option to specify a subfolder for multi-concept training.\n",
        "# @markdown > Specify `--all` to process all subfolders/`recursive`\n",
        "sub_folder  = \"\" #@param {type: \"string\"}\n",
        "# @markdown Enable this to append custom tags at the end of lines.\n",
        "append      = False  # @param {type:\"boolean\"}\n",
        "# @markdown Enable this if you want to remove captions/tags instead.\n",
        "remove_tag  = False  # @param {type:\"boolean\"}\n",
        "recursive   = False\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder == \"--all\":\n",
        "    image_dir = train_data_dir\n",
        "    recursive = True\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def process_tags(filename, custom_tag, append, remove_tag):\n",
        "    contents = read_file(filename)\n",
        "    tags = [tag.strip() for tag in contents.split(',')]\n",
        "    custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
        "\n",
        "    for custom_tag in custom_tags:\n",
        "        custom_tag = custom_tag.replace(\"_\", \" \")\n",
        "        if remove_tag:\n",
        "            while custom_tag in tags:\n",
        "                tags.remove(custom_tag)\n",
        "        else:\n",
        "            if custom_tag not in tags:\n",
        "                if append:\n",
        "                    tags.append(custom_tag)\n",
        "                else:\n",
        "                    tags.insert(0, custom_tag)\n",
        "\n",
        "    contents = ', '.join(tags)\n",
        "    write_file(filename, contents)\n",
        "\n",
        "def process_directory(image_dir, tag, append, remove_tag, recursive):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "\n",
        "        if os.path.isdir(file_path) and recursive:\n",
        "            process_directory(file_path, tag, append, remove_tag, recursive)\n",
        "        elif filename.endswith(extension):\n",
        "            process_tags(file_path, tag, append, remove_tag)\n",
        "\n",
        "tag = custom_tag\n",
        "\n",
        "if not any(\n",
        "    [filename.endswith(extension) for filename in os.listdir(image_dir)]\n",
        "):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")):\n",
        "            open(\n",
        "                os.path.join(image_dir, filename.split(\".\")[0] + extension),\n",
        "                \"w\",\n",
        "            ).close()\n",
        "\n",
        "if custom_tag:\n",
        "    process_directory(image_dir, tag, append, remove_tag, recursive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "hhgatqF3leHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b9c729-6341-4682-ff33-c388f9171231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 images.\n",
            "Creating a new metadata file\n",
            "Merging tags and captions into metadata json.\n",
            "100% 120/120 [00:00<00:00, 260.79it/s]\n",
            "All 120 images have captions\n",
            "60/120 images have tags\n",
            "Writing metadata: /content/LoRA/meta_clean.json\n",
            "Done!\n",
            "found 120 images.\n",
            "loading existing metadata: /content/LoRA/meta_clean.json\n",
            "load VAE: /content/vae/sdxl_vae.safetensors\n",
            "100% 120/120 [02:33<00:00,  1.28s/it]\n",
            "bucket 0 (1024, 1024): 120\n",
            "mean ar error: 0.0\n",
            "writing metadata: /content/LoRA/meta_lat.json\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# @title ## **3.4. Bucketing and Latents Caching**\n",
        "%store -r\n",
        "\n",
        "# @markdown This code will create buckets based on the `bucket_resolution` provided for multi-aspect ratio training, and then convert all images within the `train_data_dir` to latents.\n",
        "bucketing_json    = os.path.join(training_dir, \"meta_lat.json\")\n",
        "metadata_json     = os.path.join(training_dir, \"meta_clean.json\")\n",
        "bucket_resolution = 1024  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "mixed_precision   = \"no\"  # @param [\"no\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "skip_existing     = False  # @param{type:\"boolean\"}\n",
        "flip_aug          = False  # @param{type:\"boolean\"}\n",
        "# @markdown Use `clean_caption` option to clean such as duplicate tags, `women` to `girl`, etc\n",
        "clean_caption     = False #@param {type:\"boolean\"}\n",
        "#@markdown Use the `recursive` option to process subfolders as well\n",
        "recursive         = True #@param {type:\"boolean\"}\n",
        "\n",
        "metadata_config = {\n",
        "    \"_train_data_dir\": train_data_dir,\n",
        "    \"_out_json\": metadata_json,\n",
        "    \"recursive\": recursive,\n",
        "    \"full_path\": recursive,\n",
        "    \"clean_caption\": clean_caption\n",
        "}\n",
        "\n",
        "bucketing_config = {\n",
        "    \"_train_data_dir\": train_data_dir,\n",
        "    \"_in_json\": metadata_json,\n",
        "    \"_out_json\": bucketing_json,\n",
        "    \"_model_name_or_path\": vae_path if vae_path else model_path,\n",
        "    \"recursive\": recursive,\n",
        "    \"full_path\": recursive,\n",
        "    \"flip_aug\": flip_aug,\n",
        "    \"skip_existing\": skip_existing,\n",
        "    \"batch_size\": 4,\n",
        "    \"max_data_loader_n_workers\": 2,\n",
        "    \"max_resolution\": f\"{bucket_resolution}, {bucket_resolution}\",\n",
        "    \"mixed_precision\": mixed_precision,\n",
        "}\n",
        "\n",
        "def generate_args(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "    return args.strip()\n",
        "\n",
        "merge_metadata_args = generate_args(metadata_config)\n",
        "prepare_buckets_args = generate_args(bucketing_config)\n",
        "\n",
        "merge_metadata_command = f\"python merge_all_to_metadata.py {merge_metadata_args}\"\n",
        "prepare_buckets_command = f\"python prepare_buckets_latents.py {prepare_buckets_args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{merge_metadata_command}\n",
        "time.sleep(1)\n",
        "!{prepare_buckets_command}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAZVkLuaRJ9e"
      },
      "source": [
        "# **IV. Training**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "cJgLfRtlHSjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cddd9f32-2136-4c1b-81a9-ac47176c97a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 32\n",
            "network_alpha = 16\n",
            "network_args = []\n",
            "network_train_unet_only = true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import toml\n",
        "\n",
        "# @title ## **4.1. LoRa: Low-Rank Adaptation Config**\n",
        "# @markdown Kohya's `LoRA` renamed to `LoRA-LierLa` and Kohya's `LoCon` renamed to `LoRA-C3Lier`, read [official announcement](https://github.com/kohya-ss/sd-scripts/blob/849bc24d205a35fbe1b2a4063edd7172533c1c01/README.md#naming-of-lora).\n",
        "network_category = \"LoRA_LierLa\"  # @param [\"LoRA_LierLa\", \"LoRA_C3Lier\", \"DyLoRA_LierLa\", \"DyLoRA_C3Lier\", \"LoCon\", \"LoHa\", \"IA3\", \"LoKR\", \"DyLoRA_Lycoris\"]\n",
        "\n",
        "# @markdown | network_category | network_dim | network_alpha | conv_dim | conv_alpha | unit |\n",
        "# @markdown | :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "# @markdown | LoRA-LierLa | 32 | 1 | - | - | - |\n",
        "# @markdown | LoCon/LoRA-C3Lier | 16 | 8 | 8 | 1 | - |\n",
        "# @markdown | LoHa | 8 | 4 | 4 | 1 | - |\n",
        "# @markdown | Other Category | ? | ? | ? | ? | - |\n",
        "\n",
        "# @markdown Specify `network_args` to add `optional` training args, like for specifying each 25 block weight, read [this](https://github.com/kohya-ss/sd-scripts/blob/main/train_network_README-ja.md#%E9%9A%8E%E5%B1%A4%E5%88%A5%E5%AD%A6%E7%BF%92%E7%8E%87)\n",
        "network_args    = \"\"  # @param {'type':'string'}\n",
        "\n",
        "# @markdown ### **Linear Layer Config**\n",
        "# @markdown Used by all `network_category`. When in doubt, set `network_dim = network_alpha`\n",
        "network_dim     = 32  # @param {'type':'number'}\n",
        "network_alpha   = 16  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **Convolutional Layer Config**\n",
        "# @markdown Only required if `network_category` is not `LoRA_LierLa`, as it involves training convolutional layers in addition to linear layers.\n",
        "conv_dim        = 32  # @param {'type':'number'}\n",
        "conv_alpha      = 16  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **DyLoRA Config**\n",
        "# @markdown Only required if `network_category` is `DyLoRA_LierLa` and `DyLoRA_C3Lier`\n",
        "unit = 4  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(network_args, str):\n",
        "    network_args = network_args.strip()\n",
        "    if network_args.startswith('[') and network_args.endswith(']'):\n",
        "        try:\n",
        "            network_args = ast.literal_eval(network_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing network_args: {e}\\n\")\n",
        "            network_args = []\n",
        "    elif len(network_args) > 0:\n",
        "        print(f\"WARNING! '{network_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        network_args = []\n",
        "    else:\n",
        "        network_args = []\n",
        "else:\n",
        "    network_args = []\n",
        "\n",
        "network_config = {\n",
        "    \"LoRA_LierLa\": {\n",
        "        \"module\": \"networks.lora\",\n",
        "        \"args\"  : []\n",
        "    },\n",
        "    \"LoRA_C3Lier\": {\n",
        "        \"module\": \"networks.lora\",\n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_LierLa\": {\n",
        "        \"module\": \"networks.dylora\",\n",
        "        \"args\"  : [\n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_C3Lier\": {\n",
        "        \"module\": \"networks.dylora\",\n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\",\n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoCon\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=locon\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoHa\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=loha\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"IA3\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=ia3\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoKR\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=lokr\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_Lycoris\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=dylora\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "network_module = network_config[network_category][\"module\"]\n",
        "network_args.extend(network_config[network_category][\"args\"])\n",
        "\n",
        "lora_config = {\n",
        "    \"additional_network_arguments\": {\n",
        "        \"no_metadata\"                     : False,\n",
        "        \"network_module\"                  : network_module,\n",
        "        \"network_dim\"                     : network_dim,\n",
        "        \"network_alpha\"                   : network_alpha,\n",
        "        \"network_args\"                    : network_args,\n",
        "        \"network_train_unet_only\"         : True,\n",
        "        \"training_comment\"                : None,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(toml.dumps(lora_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "JNlw3u8arwir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22628fde-9910-4be8-9c45-3868016f3d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdaFactor\"\n",
            "learning_rate = 0.0001\n",
            "max_grad_norm = 0\n",
            "optimizer_args = [ \"scale_parameter=False\", \"relative_step=False\", \"warmup_init=False\",]\n",
            "lr_scheduler = \"constant_with_warmup\"\n",
            "lr_warmup_steps = 100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import toml\n",
        "import ast\n",
        "\n",
        "# @title ## **4.2. Optimizer Config**\n",
        "# @markdown Use `Adafactor` optimizer. `RMSprop 8bit` or `Adagrad 8bit` may work. `AdamW 8bit` doesn't seem to work.\n",
        "optimizer_type = \"AdaFactor\"  # @param [\"AdamW\", \"AdamW8bit\", \"Lion8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation(DAdaptAdamPreprint)\", \"DAdaptAdaGrad\", \"DAdaptAdam\", \"DAdaptAdan\", \"DAdaptAdanIP\", \"DAdaptLion\", \"DAdaptSGD\", \"AdaFactor\"]\n",
        "# @markdown Specify `optimizer_args` to add `additional` args for optimizer, e.g: `[\"weight_decay=0.6\"]`\n",
        "optimizer_args = \"[ \\\"scale_parameter=False\\\", \\\"relative_step=False\\\", \\\"warmup_init=False\\\" ]\"  # @param {'type':'string'}\n",
        "# @markdown ### **Learning Rate Config**\n",
        "# @markdown Different `optimizer_type` and `network_category` for some condition requires different learning rate. It's recommended to set `text_encoder_lr = 1/2 * unet_lr`\n",
        "learning_rate = 1e-4  # @param {'type':'number'}\n",
        "# @markdown ### **LR Scheduler Config**\n",
        "# @markdown `lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs.\n",
        "lr_scheduler = \"constant_with_warmup\"  # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"] {allow-input: false}\n",
        "lr_warmup_steps = 100  # @param {'type':'number'}\n",
        "# @markdown Specify `lr_scheduler_num` with `num_cycles` value for `cosine_with_restarts` or `power` value for `polynomial`\n",
        "lr_scheduler_num = 0  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(optimizer_args, str):\n",
        "    optimizer_args = optimizer_args.strip()\n",
        "    if optimizer_args.startswith('[') and optimizer_args.endswith(']'):\n",
        "        try:\n",
        "            optimizer_args = ast.literal_eval(optimizer_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing optimizer_args: {e}\\n\")\n",
        "            optimizer_args = []\n",
        "    elif len(optimizer_args) > 0:\n",
        "        print(f\"WARNING! '{optimizer_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        optimizer_args = []\n",
        "    else:\n",
        "        optimizer_args = []\n",
        "else:\n",
        "    optimizer_args = []\n",
        "\n",
        "optimizer_config = {\n",
        "    \"optimizer_arguments\": {\n",
        "        \"optimizer_type\"          : optimizer_type,\n",
        "        \"learning_rate\"           : learning_rate,\n",
        "        \"max_grad_norm\"           : 0,\n",
        "        \"optimizer_args\"          : optimizer_args,\n",
        "        \"lr_scheduler\"            : lr_scheduler,\n",
        "        \"lr_warmup_steps\"         : lr_warmup_steps,\n",
        "        \"lr_scheduler_num_cycles\" : lr_scheduler_num if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\"      : lr_scheduler_num if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_scheduler_type\"       : None,\n",
        "        \"lr_scheduler_args\"       : None,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(toml.dumps(optimizer_config))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "YOxNM0x7dvfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00725e0-4946-4914-b395-40cacd3c68c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[advanced_training_config]\n",
            "resume = \"\"\n",
            "save_state = true\n",
            "save_last_n_epochs_state = true\n",
            "noise_offset = 0.1\n",
            "adaptive_noise_scale = 0.01\n",
            "caption_dropout_rate = 0\n",
            "caption_tag_dropout_rate = 0.5\n",
            "caption_dropout_every_n_epochs = 0\n",
            "min_snr_gamma = 5\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title ## **4.3. Advanced Training Config** (Optional)\n",
        "import toml\n",
        "\n",
        "\n",
        "# @markdown ### **Optimizer State Config**\n",
        "save_optimizer_state      = True #@param {type:\"boolean\"}\n",
        "load_optimizer_state      = \"\" #@param {type:\"string\"}\n",
        "# @markdown ### **Noise Control**\n",
        "noise_control_type        = \"noise_offset\" #@param [\"none\", \"noise_offset\", \"multires_noise\"]\n",
        "# @markdown #### **a. Noise Offset**\n",
        "# @markdown Control and easily generating darker or light images by offset the noise when fine-tuning the model. Recommended value: `0.1`. Read [Diffusion With Offset Noise](https://www.crosslabs.org//blog/diffusion-with-offset-noise)\n",
        "noise_offset_num          = 0.1  # @param {type:\"number\"}\n",
        "# @markdown **[Experimental]**\n",
        "# @markdown Automatically adjusts the noise offset based on the absolute mean values of each channel in the latents when used with `--noise_offset`. Specify a value around 1/10 to the same magnitude as the `--noise_offset` for best results. Set `0` to disable.\n",
        "adaptive_noise_scale      = 0.01 # @param {type:\"number\"}\n",
        "# @markdown #### **b. Multires Noise**\n",
        "# @markdown enable multires noise with this number of iterations (if enabled, around 6-10 is recommended)\n",
        "multires_noise_iterations = 6 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "multires_noise_discount = 0.3 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "# @markdown ### **Caption Dropout**\n",
        "caption_dropout_rate = 0  # @param {type:\"number\"}\n",
        "caption_tag_dropout_rate = 0.5  # @param {type:\"number\"}\n",
        "caption_dropout_every_n_epochs = 0  # @param {type:\"number\"}\n",
        "# @markdown ### **Custom Train Function**\n",
        "# @markdown Gamma for reducing the weight of high-loss timesteps. Lower numbers have a stronger effect. The paper recommends `5`. Read the paper [here](https://arxiv.org/abs/2303.09556).\n",
        "min_snr_gamma             = 5 #@param {type:\"number\"}\n",
        "\n",
        "advanced_training_config = {\n",
        "    \"advanced_training_config\": {\n",
        "        \"resume\"                        : load_optimizer_state,\n",
        "        \"save_state\"                    : save_optimizer_state,\n",
        "        \"save_last_n_epochs_state\"      : save_optimizer_state,\n",
        "        \"noise_offset\"                  : noise_offset_num if noise_control_type == \"noise_offset\" else None,\n",
        "        \"adaptive_noise_scale\"          : adaptive_noise_scale if adaptive_noise_scale and noise_control_type == \"noise_offset\" else None,\n",
        "        \"multires_noise_iterations\"     : multires_noise_iterations if noise_control_type ==\"multires_noise\" else None,\n",
        "        \"multires_noise_discount\"       : multires_noise_discount if noise_control_type ==\"multires_noise\" else None,\n",
        "        \"caption_dropout_rate\"          : caption_dropout_rate,\n",
        "        \"caption_tag_dropout_rate\"      : caption_tag_dropout_rate,\n",
        "        \"caption_dropout_every_n_epochs\": caption_dropout_every_n_epochs,\n",
        "        \"min_snr_gamma\"                 : min_snr_gamma if not min_snr_gamma == -1 else None,\n",
        "    }\n",
        "}\n",
        "\n",
        "print(toml.dumps(advanced_training_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-Z4w3lfFKLjr",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb9ecce2-9c79-4cb6-cb6c-130c8be4ea59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[sdxl_arguments]\n",
            "cache_text_encoder_outputs = false\n",
            "no_half_vae = true\n",
            "min_timestep = 0\n",
            "max_timestep = 1000\n",
            "shuffle_caption = true\n",
            "lowram = true\n",
            "\n",
            "[model_arguments]\n",
            "pretrained_model_name_or_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
            "vae = \"/content/vae/sdxl_vae.safetensors\"\n",
            "\n",
            "[dataset_arguments]\n",
            "debug_dataset = false\n",
            "in_json = \"/content/LoRA/meta_lat.json\"\n",
            "train_data_dir = \"/content/drive/MyDrive/Loras/andyflinn\"\n",
            "dataset_repeats = 1\n",
            "keep_tokens = 0\n",
            "resolution = \"1024,1024\"\n",
            "color_aug = false\n",
            "token_warmup_min = 1\n",
            "token_warmup_step = 0\n",
            "\n",
            "[training_arguments]\n",
            "output_dir = \"/content/drive/MyDrive/kohya-trainer/output/sdxl_lora_andyflinn\"\n",
            "output_name = \"sdxl_lora_andyflinn\"\n",
            "save_precision = \"fp16\"\n",
            "save_every_n_epochs = 1\n",
            "train_batch_size = 4\n",
            "max_token_length = 225\n",
            "mem_eff_attn = false\n",
            "sdpa = true\n",
            "xformers = false\n",
            "max_train_epochs = 10\n",
            "max_data_loader_n_workers = 8\n",
            "persistent_data_loader_workers = true\n",
            "gradient_checkpointing = true\n",
            "gradient_accumulation_steps = 1\n",
            "mixed_precision = \"fp16\"\n",
            "\n",
            "[logging_arguments]\n",
            "log_with = \"wandb\"\n",
            "log_tracker_name = \"sdxl_lora_andyflinn\"\n",
            "logging_dir = \"/content/LoRA/logs\"\n",
            "\n",
            "[sample_prompt_arguments]\n",
            "sample_every_n_epochs = 1\n",
            "sample_sampler = \"euler_a\"\n",
            "\n",
            "[saving_arguments]\n",
            "save_model_as = \"safetensors\"\n",
            "\n",
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdaFactor\"\n",
            "learning_rate = 0.0001\n",
            "max_grad_norm = 0\n",
            "optimizer_args = [ \"scale_parameter=False\", \"relative_step=False\", \"warmup_init=False\",]\n",
            "lr_scheduler = \"constant_with_warmup\"\n",
            "lr_warmup_steps = 100\n",
            "\n",
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 32\n",
            "network_alpha = 16\n",
            "network_args = []\n",
            "network_train_unet_only = true\n",
            "\n",
            "[advanced_training_config]\n",
            "save_state = true\n",
            "save_last_n_epochs_state = true\n",
            "noise_offset = 0.1\n",
            "adaptive_noise_scale = 0.01\n",
            "caption_dropout_rate = 0\n",
            "caption_tag_dropout_rate = 0.5\n",
            "caption_dropout_every_n_epochs = 0\n",
            "min_snr_gamma = 5\n",
            "\n",
            "[prompt]\n",
            "negative_prompt = \"3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\"\n",
            "width = 1024\n",
            "height = 1024\n",
            "scale = 12\n",
            "sample_steps = 28\n",
            "[[prompt.subset]]\n",
            "prompt = \"andyflinn, a man, hat, glasses\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title ## **4.4. Training Config**\n",
        "import toml\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown ### **Project Config**\n",
        "project_name                = \"sdxl_lora_andyflinn\"  # @param {type:\"string\"}\n",
        "# @markdown Get your `wandb_api_key` [here](https://wandb.ai/settings) to logs with wandb.\n",
        "wandb_api_key               = \"ffb2849473332017dea8738e3482165e87ecd9c1\" # @param {type:\"string\"}\n",
        "in_json                     = \"/content/LoRA/meta_lat.json\"  # @param {type:\"string\"}\n",
        "# @markdown ### **SDXL Config**\n",
        "gradient_checkpointing      = True  # @param {type:\"boolean\"}\n",
        "no_half_vae                 = True  # @param {type:\"boolean\"}\n",
        "#@markdown Recommended parameter for SDXL training but if you enable it, `shuffle_caption` won't work\n",
        "cache_text_encoder_outputs  = False  # @param {type:\"boolean\"}\n",
        "#@markdown These options can be used to train U-Net with different timesteps. The default values are 0 and 1000.\n",
        "min_timestep                = 0 # @param {type:\"number\"}\n",
        "max_timestep                = 1000 # @param {type:\"number\"}\n",
        "# @markdown ### **Dataset Config**\n",
        "num_repeats                 = 1  # @param {type:\"number\"}\n",
        "resolution                  = 1024  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "keep_tokens                 = 0  # @param {type:\"number\"}\n",
        "# @markdown ### **General Config**\n",
        "num_epochs                  = 10  # @param {type:\"number\"}\n",
        "train_batch_size            = 4  # @param {type:\"number\"}\n",
        "mixed_precision             = \"fp16\"  # @param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "seed                        = -1  # @param {type:\"number\"}\n",
        "optimization                = \"scaled dot-product attention\" # @param [\"xformers\", \"scaled dot-product attention\"]\n",
        "# @markdown ### **Save Output Config**\n",
        "save_precision              = \"fp16\"  # @param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs         = 1  # @param {type:\"number\"}\n",
        "# @markdown ### **Sample Prompt Config**\n",
        "enable_sample               = True  # @param {type:\"boolean\"}\n",
        "sampler                     = \"euler_a\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "positive_prompt             = \"\"\n",
        "negative_prompt             = \"\"\n",
        "quality_prompt              = \"Stable Diffusion XL\"  # @param [\"None\", \"Waifu Diffusion 1.5\", \"NovelAI\", \"AbyssOrangeMix\", \"Stable Diffusion XL\"] {allow-input: false}\n",
        "if quality_prompt          == \"NovelAI\":\n",
        "    positive_prompt         = \"masterpiece, best quality, \"\n",
        "    negative_prompt         = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, \"\n",
        "if quality_prompt          == \"AbyssOrangeMix\":\n",
        "    positive_prompt         = \"masterpiece, best quality, \"\n",
        "    negative_prompt         = \"(worst quality, low quality:1.4), \"\n",
        "if quality_prompt          == \"Stable Diffusion XL\":\n",
        "    negative_prompt         = \"3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\"\n",
        "custom_prompt               = \"andyflinn, a man, hat, glasses\" # @param {type:\"string\"}\n",
        "# @markdown Specify `prompt_from_caption` if you want to use caption as prompt instead. Will be chosen randomly.\n",
        "prompt_from_caption         = \"none\"  # @param [\"none\", \".txt\", \".caption\"]\n",
        "if prompt_from_caption     != \"none\":\n",
        "    custom_prompt           = \"\"\n",
        "num_prompt                  = 2  # @param {type:\"number\"}\n",
        "logging_dir                 = os.path.join(training_dir, \"logs\")\n",
        "lowram                      = int(next(line.split()[1] for line in open('/proc/meminfo') if \"MemTotal\" in line)) / (1024**2) < 15\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "prompt_config = {\n",
        "    \"prompt\": {\n",
        "        \"negative_prompt\" : negative_prompt,\n",
        "        \"width\"           : resolution,\n",
        "        \"height\"          : resolution,\n",
        "        \"scale\"           : 12,\n",
        "        \"sample_steps\"    : 28,\n",
        "        \"subset\"          : [],\n",
        "    }\n",
        "}\n",
        "\n",
        "train_config = {\n",
        "    \"sdxl_arguments\": {\n",
        "        \"cache_text_encoder_outputs\" : cache_text_encoder_outputs,\n",
        "        \"no_half_vae\"                : True,\n",
        "        \"min_timestep\"               : min_timestep,\n",
        "        \"max_timestep\"               : max_timestep,\n",
        "        \"shuffle_caption\"            : True if not cache_text_encoder_outputs else False,\n",
        "        \"lowram\"                     : lowram\n",
        "    },\n",
        "    \"model_arguments\": {\n",
        "        \"pretrained_model_name_or_path\" : model_path,\n",
        "        \"vae\"                           : vae_path,\n",
        "    },\n",
        "    \"dataset_arguments\": {\n",
        "        \"debug_dataset\"                 : False,\n",
        "        \"in_json\"                       : in_json,\n",
        "        \"train_data_dir\"                : train_data_dir,\n",
        "        \"dataset_repeats\"               : num_repeats,\n",
        "        \"keep_tokens\"                   : keep_tokens,\n",
        "        \"resolution\"                    : str(resolution) + ',' + str(resolution),\n",
        "        \"color_aug\"                     : False,\n",
        "        \"face_crop_aug_range\"           : None,\n",
        "        \"token_warmup_min\"              : 1,\n",
        "        \"token_warmup_step\"             : 0,\n",
        "    },\n",
        "    \"training_arguments\": {\n",
        "        \"output_dir\"                    : os.path.join(output_dir, project_name),\n",
        "        \"output_name\"                   : project_name if project_name else \"last\",\n",
        "        \"save_precision\"                : save_precision,\n",
        "        \"save_every_n_epochs\"           : save_every_n_epochs,\n",
        "        \"save_n_epoch_ratio\"            : None,\n",
        "        \"save_last_n_epochs\"            : None,\n",
        "        \"resume\"                        : None,\n",
        "        \"train_batch_size\"              : train_batch_size,\n",
        "        \"max_token_length\"              : 225,\n",
        "        \"mem_eff_attn\"                  : False,\n",
        "        \"sdpa\"                          : True if optimization == \"scaled dot-product attention\" else False,\n",
        "        \"xformers\"                      : True if optimization == \"xformers\" else False,\n",
        "        \"max_train_epochs\"              : num_epochs,\n",
        "        \"max_data_loader_n_workers\"     : 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"seed\"                          : seed if seed > 0 else None,\n",
        "        \"gradient_checkpointing\"        : gradient_checkpointing,\n",
        "        \"gradient_accumulation_steps\"   : 1,\n",
        "        \"mixed_precision\"               : mixed_precision,\n",
        "    },\n",
        "    \"logging_arguments\": {\n",
        "        \"log_with\"          : \"wandb\" if wandb_api_key else \"tensorboard\",\n",
        "        \"log_tracker_name\"  : project_name if wandb_api_key and not project_name == \"last\" else None,\n",
        "        \"logging_dir\"       : logging_dir,\n",
        "        \"log_prefix\"        : project_name if not wandb_api_key else None,\n",
        "    },\n",
        "    \"sample_prompt_arguments\": {\n",
        "        \"sample_every_n_steps\"    : None,\n",
        "        \"sample_every_n_epochs\"   : save_every_n_epochs if enable_sample else None,\n",
        "        \"sample_sampler\"          : sampler,\n",
        "    },\n",
        "    \"saving_arguments\": {\n",
        "        \"save_model_as\": \"safetensors\"\n",
        "    },\n",
        "}\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt):\n",
        "    if enable_sample:\n",
        "        search_pattern = os.path.join(train_data_dir, '**/*' + prompt_from_caption)\n",
        "        caption_files = glob.glob(search_pattern, recursive=True)\n",
        "\n",
        "        if not caption_files:\n",
        "            if not custom_prompt:\n",
        "                custom_prompt = \"masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\"\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = [\n",
        "                {\"prompt\": positive_prompt + custom_prompt if positive_prompt else custom_prompt}\n",
        "            ]\n",
        "        else:\n",
        "            selected_files = random.sample(caption_files, min(num_prompt, len(caption_files)))\n",
        "\n",
        "            prompts = []\n",
        "            for file in selected_files:\n",
        "                with open(file, 'r') as f:\n",
        "                    prompts.append(f.read().strip())\n",
        "\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = []\n",
        "\n",
        "            for prompt in prompts:\n",
        "                new_prompt = {\n",
        "                    \"prompt\": positive_prompt + prompt if positive_prompt else prompt,\n",
        "                }\n",
        "                new_prompt_config['prompt']['subset'].append(new_prompt)\n",
        "\n",
        "        return new_prompt_config\n",
        "    else:\n",
        "        return prompt_config\n",
        "\n",
        "def eliminate_none_variable(config):\n",
        "    for key in config:\n",
        "        if isinstance(config[key], dict):\n",
        "            for sub_key in config[key]:\n",
        "                if config[key][sub_key] == \"\":\n",
        "                    config[key][sub_key] = None\n",
        "        elif config[key] == \"\":\n",
        "            config[key] = None\n",
        "\n",
        "    return config\n",
        "\n",
        "try:\n",
        "    train_config.update(optimizer_config)\n",
        "except NameError:\n",
        "    raise NameError(\"'optimizer_config' dictionary is missing. Please run  '4.1. Optimizer Config' cell.\")\n",
        "\n",
        "try:\n",
        "    train_config.update(lora_config)\n",
        "except NameError:\n",
        "    raise NameError(\"'lora_config' dictionary is missing. Please run  '4.1. LoRa: Low-Rank Adaptation Config' cell.\")\n",
        "\n",
        "advanced_training_warning = False\n",
        "try:\n",
        "    train_config.update(advanced_training_config)\n",
        "except NameError:\n",
        "    advanced_training_warning = True\n",
        "    pass\n",
        "\n",
        "prompt_config = prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt)\n",
        "\n",
        "config_path         = os.path.join(config_dir, \"config_file.toml\")\n",
        "prompt_path         = os.path.join(config_dir, \"sample_prompt.toml\")\n",
        "\n",
        "config_str          = toml.dumps(eliminate_none_variable(train_config))\n",
        "prompt_str          = toml.dumps(eliminate_none_variable(prompt_config))\n",
        "\n",
        "write_file(config_path, config_str)\n",
        "write_file(prompt_path, prompt_str)\n",
        "\n",
        "print(config_str)\n",
        "\n",
        "if advanced_training_warning:\n",
        "    import textwrap\n",
        "    error_message = \"WARNING: This is not an error message, but the [advanced_training_config] dictionary is missing. Please run the '4.2. Advanced Training Config' cell if you intend to use it, or continue to the next step.\"\n",
        "    wrapped_message = textwrap.fill(error_message, width=80)\n",
        "    print('\\033[38;2;204;102;102m' + wrapped_message + '\\033[0m\\n')\n",
        "    pass\n",
        "\n",
        "print(prompt_str)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vhtDOMtG7qd"
      },
      "source": [
        "## V. Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "t4OhkX7Dz7CH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d2f253-36e9-4804-fb41-5416fbe0c383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load Diffusers pretrained models: stabilityai/stable-diffusion-xl-base-1.0, variant=fp16\n",
            "Downloading (…)ain/model_index.json: 100% 609/609 [00:00<00:00, 2.31MB/s]\n",
            "Fetching 23 files:   0% 0/23 [00:00<?, ?it/s]\n",
            "Downloading (…)cheduler_config.json: 100% 479/479 [00:00<00:00, 2.09MB/s]\n",
            "Fetching 23 files:   9% 2/23 [00:01<00:12,  1.72it/s]\n",
            "Downloading (…)_encoder/config.json: 100% 565/565 [00:00<00:00, 1.57MB/s]\n",
            "\n",
            "Downloading (…)kenizer_2/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 1.61MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)ncoder_2/config.json: 100% 575/575 [00:00<00:00, 2.34MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 725/725 [00:00<00:00, 2.02MB/s]\n",
            "Downloading (…)kenizer_2/merges.txt: 100% 525k/525k [00:00<00:00, 5.40MB/s]\n",
            "\n",
            "Downloading (…)kenizer_2/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)37e/unet/config.json: 100% 1.68k/1.68k [00:00<00:00, 5.68MB/s]\n",
            "Downloading (…)kenizer_2/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 12.5MB/s]\n",
            "\n",
            "Downloading (…)a37e/vae/config.json: 100% 642/642 [00:00<00:00, 2.43MB/s]\n",
            "\n",
            "Downloading (…)/vae_1_0/config.json: 100% 607/607 [00:00<00:00, 2.16MB/s]\n",
            "\n",
            "Downloading model.fp16.safetensors:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading model.fp16.safetensors:   4% 10.5M/246M [00:00<00:05, 40.5MB/s]\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   0% 0.00/1.39G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/493M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   1% 10.5M/1.39G [00:00<00:47, 28.9MB/s]\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:   9% 21.0M/246M [00:00<00:10, 21.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/1.04M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 0.00/5.14G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:   2% 10.5M/493M [00:00<00:21, 22.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/7.29M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 1.04M/1.04M [00:00<00:00, 6.12MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx: 100% 1.04M/1.04M [00:00<00:00, 4.97MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 7.29M/7.29M [00:00<00:00, 16.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 10.5M/167M [00:00<00:03, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/198M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  13% 31.5M/246M [00:01<00:10, 19.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 10.5M/5.14G [00:00<04:33, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:   4% 21.0M/493M [00:01<00:24, 18.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/137M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 10.5M/167M [00:00<00:10, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   2% 31.5M/1.39G [00:01<01:09, 19.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   5% 10.5M/198M [00:00<00:08, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   8% 10.5M/137M [00:00<00:04, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 21.0M/167M [00:00<00:06, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 21.0M/5.14G [00:01<05:02, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  17% 41.9M/246M [00:02<00:11, 17.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:   6% 31.5M/493M [00:02<00:31, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   3% 41.9M/1.39G [00:02<01:18, 17.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 21.0M/167M [00:01<00:11, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 31.5M/167M [00:01<00:06, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 31.5M/5.14G [00:01<05:00, 17.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  11% 21.0M/198M [00:01<00:11, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  21% 52.4M/246M [00:02<00:11, 17.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:   9% 41.9M/493M [00:02<00:25, 17.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  15% 21.0M/137M [00:01<00:07, 15.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   4% 52.4M/1.39G [00:02<01:05, 20.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 31.5M/167M [00:02<00:08, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 41.9M/167M [00:03<00:11, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 41.9M/5.14G [00:03<08:31, 9.95MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  11% 52.4M/493M [00:04<00:42, 10.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  26% 62.9M/246M [00:04<00:17, 10.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  16% 31.5M/198M [00:03<00:19, 8.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   5% 62.9M/1.39G [00:04<02:01, 10.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 41.9M/167M [00:03<00:12, 9.91MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  31% 52.4M/167M [00:03<00:08, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  23% 31.5M/137M [00:03<00:12, 8.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 52.4M/5.14G [00:03<06:33, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  13% 62.9M/493M [00:04<00:34, 12.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  30% 73.4M/246M [00:05<00:14, 12.3MB/s]\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   5% 73.4M/1.39G [00:04<01:39, 13.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  21% 41.9M/198M [00:03<00:14, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  38% 62.9M/167M [00:04<00:06, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  31% 52.4M/167M [00:04<00:09, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 62.9M/5.14G [00:04<05:25, 15.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  31% 41.9M/137M [00:03<00:08, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  15% 73.4M/493M [00:04<00:26, 16.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   6% 83.9M/1.39G [00:05<01:20, 16.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  26% 52.4M/198M [00:04<00:10, 14.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  34% 83.9M/246M [00:05<00:11, 14.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  44% 73.4M/167M [00:04<00:05, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  38% 62.9M/167M [00:04<00:07, 14.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 73.4M/5.14G [00:04<04:52, 17.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  38% 52.4M/137M [00:04<00:06, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  17% 83.9M/493M [00:05<00:22, 17.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   7% 94.4M/1.39G [00:05<01:22, 15.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  32% 62.9M/198M [00:04<00:09, 14.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  38% 94.4M/246M [00:06<00:10, 14.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  44% 73.4M/167M [00:05<00:06, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  19% 94.4M/493M [00:05<00:22, 18.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  50% 83.9M/167M [00:05<00:05, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   2% 83.9M/5.14G [00:05<05:04, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  46% 62.9M/137M [00:04<00:05, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  37% 73.4M/198M [00:05<00:07, 17.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   8% 105M/1.39G [00:06<01:14, 17.3MB/s] \u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  43% 105M/246M [00:06<00:09, 15.6MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  56% 94.4M/167M [00:05<00:04, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  50% 83.9M/167M [00:05<00:05, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  21% 105M/493M [00:06<00:21, 18.2MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   2% 94.4M/5.14G [00:06<04:51, 17.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  54% 73.4M/137M [00:05<00:04, 15.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  42% 83.9M/198M [00:05<00:06, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  47% 115M/246M [00:07<00:07, 17.3MB/s]\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   8% 115M/1.39G [00:06<01:12, 17.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  56% 94.4M/167M [00:06<00:04, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  23% 115M/493M [00:07<00:21, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   2% 105M/5.14G [00:06<05:06, 16.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  63% 105M/167M [00:06<00:04, 14.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  61% 83.9M/137M [00:07<00:05, 9.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  48% 94.4M/198M [00:07<00:10, 9.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  63% 105M/167M [00:08<00:06, 10.0MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  26% 126M/493M [00:09<00:34, 10.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:   9% 126M/1.39G [00:09<02:09, 9.75MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  69% 115M/167M [00:08<00:04, 10.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   2% 115M/5.14G [00:08<08:16, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  69% 94.4M/137M [00:08<00:03, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  53% 105M/198M [00:08<00:07, 12.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  28% 136M/493M [00:09<00:26, 13.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  69% 115M/167M [00:08<00:04, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  10% 136M/1.39G [00:09<01:42, 12.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  75% 126M/167M [00:08<00:03, 12.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   2% 126M/5.14G [00:09<06:41, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  51% 126M/246M [00:10<00:14, 8.22MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  77% 105M/137M [00:08<00:02, 13.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  58% 115M/198M [00:08<00:05, 14.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  75% 126M/167M [00:09<00:03, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  30% 147M/493M [00:10<00:24, 13.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  11% 147M/1.39G [00:10<01:36, 12.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  81% 136M/167M [00:09<00:02, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  55% 136M/246M [00:10<00:11, 9.80MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  64% 126M/198M [00:09<00:04, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   3% 136M/5.14G [00:09<06:17, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  84% 115M/137M [00:09<00:01, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  81% 136M/167M [00:09<00:02, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  11% 157M/1.39G [00:10<01:25, 14.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  32% 157M/493M [00:10<00:22, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  60% 147M/246M [00:11<00:08, 11.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  88% 147M/167M [00:09<00:01, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   3% 147M/5.14G [00:10<05:50, 14.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  69% 136M/198M [00:09<00:04, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  92% 126M/137M [00:09<00:00, 14.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  88% 147M/167M [00:10<00:01, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  34% 168M/493M [00:11<00:20, 16.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  12% 168M/1.39G [00:11<01:18, 15.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  94% 157M/167M [00:10<00:00, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  64% 157M/246M [00:11<00:06, 13.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   3% 157M/5.14G [00:11<07:09, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  74% 147M/198M [00:12<00:06, 7.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  68% 168M/246M [00:14<00:10, 7.41MB/s]\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  13% 178M/1.39G [00:14<02:37, 7.67MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 136M/137M [00:12<00:00, 7.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:13<00:00, 7.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   3% 168M/5.14G [00:13<09:51, 8.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 137M/137M [00:13<00:00, 10.4MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:13<00:00, 12.3MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  94% 157M/167M [00:13<00:01, 7.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  72% 178M/246M [00:14<00:06, 9.77MB/s]\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  14% 189M/1.39G [00:14<02:00, 9.99MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  85% 168M/198M [00:13<00:02, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   3% 178M/5.14G [00:14<07:34, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  38% 189M/493M [00:14<00:30, 9.93MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  14% 199M/1.39G [00:14<01:28, 13.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:14<00:00, 9.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  77% 189M/246M [00:15<00:04, 12.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  90% 178M/198M [00:13<00:01, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:14<00:00, 11.5MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 189M/5.14G [00:14<06:46, 12.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  15% 210M/1.39G [00:15<01:20, 14.7MB/s]\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  81% 199M/246M [00:15<00:03, 14.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  95% 189M/198M [00:14<00:00, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  43% 210M/493M [00:15<00:18, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 199M/5.14G [00:15<06:10, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  16% 220M/1.39G [00:16<01:33, 12.5MB/s]\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  85% 210M/246M [00:19<00:05, 6.89MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  45% 220M/493M [00:18<00:39, 6.86MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  17% 231M/1.39G [00:18<02:27, 7.87MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  47% 231M/493M [00:18<00:27, 9.48MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  17% 241M/1.39G [00:18<01:46, 10.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  49% 241M/493M [00:18<00:19, 13.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  19% 262M/1.39G [00:19<00:59, 18.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  51% 252M/493M [00:19<00:13, 17.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  20% 283M/1.39G [00:19<00:38, 28.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  55% 273M/493M [00:19<00:08, 27.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  21% 294M/1.39G [00:19<00:33, 32.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 210M/5.14G [00:18<12:50, 6.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  89% 220M/246M [00:19<00:03, 7.93MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 198M/198M [00:18<00:00, 6.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 198M/198M [00:18<00:00, 10.5MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 220M/5.14G [00:19<10:03, 8.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  22% 304M/1.39G [00:19<00:37, 29.0MB/s]\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  94% 231M/246M [00:20<00:01, 9.72MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  60% 294M/493M [00:19<00:06, 30.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 231M/5.14G [00:19<07:27, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  23% 315M/1.39G [00:20<00:33, 32.5MB/s]\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  98% 241M/246M [00:20<00:00, 13.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   5% 241M/5.14G [00:19<05:30, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  62% 304M/493M [00:20<00:05, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors: 100% 246M/246M [00:20<00:00, 14.6MB/s]\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors: 100% 246M/246M [00:20<00:00, 11.9MB/s]\n",
            "Fetching 23 files:  17% 4/23 [00:23<02:06,  6.67s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   5% 252M/5.14G [00:19<04:12, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  64% 315M/493M [00:20<00:04, 39.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  24% 336M/1.39G [00:20<00:25, 41.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   5% 262M/5.14G [00:19<03:18, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  66% 325M/493M [00:20<00:03, 45.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  25% 346M/1.39G [00:20<00:21, 48.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  68% 336M/493M [00:20<00:02, 53.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   5% 273M/5.14G [00:20<02:38, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  70% 346M/493M [00:20<00:02, 60.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  26% 367M/1.39G [00:20<00:16, 62.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 294M/5.14G [00:20<01:52, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  72% 357M/493M [00:20<00:02, 60.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  27% 377M/1.39G [00:20<00:16, 61.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  75% 367M/493M [00:21<00:01, 65.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 304M/5.14G [00:20<01:42, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  28% 388M/1.39G [00:21<00:14, 68.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  29% 398M/1.39G [00:21<00:13, 75.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 315M/5.14G [00:20<01:37, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  79% 388M/493M [00:21<00:01, 75.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  29% 409M/1.39G [00:21<00:12, 77.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  81% 398M/493M [00:21<00:01, 75.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 325M/5.14G [00:20<01:31, 52.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  30% 419M/1.39G [00:21<00:12, 75.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  83% 409M/493M [00:21<00:01, 79.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   7% 336M/5.14G [00:21<01:22, 58.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  31% 430M/1.39G [00:21<00:12, 75.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  85% 419M/493M [00:21<00:00, 83.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   7% 346M/5.14G [00:21<01:19, 60.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  32% 440M/1.39G [00:21<00:12, 77.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  87% 430M/493M [00:21<00:00, 85.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   7% 357M/5.14G [00:23<05:26, 14.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  32% 451M/1.39G [00:23<01:03, 14.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  89% 440M/493M [00:23<00:03, 15.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   7% 367M/5.14G [00:23<04:20, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  33% 461M/1.39G [00:24<00:49, 18.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  92% 451M/493M [00:23<00:02, 19.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   7% 377M/5.14G [00:23<03:32, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  34% 472M/1.39G [00:24<00:40, 22.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  94% 461M/493M [00:24<00:01, 23.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   8% 388M/5.14G [00:23<02:56, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  35% 482M/1.39G [00:24<00:33, 27.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  96% 472M/493M [00:24<00:00, 28.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   8% 398M/5.14G [00:24<02:23, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  35% 493M/1.39G [00:24<00:26, 33.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx:  98% 482M/493M [00:24<00:00, 33.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   8% 409M/5.14G [00:24<02:02, 38.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  36% 503M/1.39G [00:24<00:23, 37.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 493M/493M [00:24<00:00, 38.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 493M/493M [00:24<00:00, 19.8MB/s]\n",
            "Fetching 23 files:  22% 5/23 [00:27<01:49,  6.06s/it]\n",
            "\n",
            "Downloading model.fp16.safetensors:  37% 514M/1.39G [00:24<00:20, 41.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   8% 430M/5.14G [00:24<01:40, 46.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  38% 524M/1.39G [00:25<00:18, 46.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   9% 440M/5.14G [00:24<01:39, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  38% 535M/1.39G [00:25<00:17, 49.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   9% 451M/5.14G [00:24<01:37, 47.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  39% 545M/1.39G [00:25<00:16, 50.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   9% 461M/5.14G [00:25<01:26, 53.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  40% 556M/1.39G [00:25<00:14, 56.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   9% 472M/5.14G [00:25<01:16, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  41% 566M/1.39G [00:25<00:13, 60.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   9% 482M/5.14G [00:25<01:09, 67.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  42% 577M/1.39G [00:25<00:12, 67.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  10% 493M/5.14G [00:25<01:03, 72.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  42% 587M/1.39G [00:26<00:11, 72.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  10% 503M/5.14G [00:25<00:59, 77.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  43% 598M/1.39G [00:26<00:10, 78.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  10% 514M/5.14G [00:25<00:56, 81.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  44% 608M/1.39G [00:26<00:09, 81.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  10% 524M/5.14G [00:25<00:57, 80.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  45% 619M/1.39G [00:26<00:10, 75.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  10% 535M/5.14G [00:26<01:04, 71.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  45% 629M/1.39G [00:26<00:10, 69.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  11% 545M/5.14G [00:26<01:08, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  46% 640M/1.39G [00:26<00:10, 68.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  11% 556M/5.14G [00:26<01:22, 55.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  47% 650M/1.39G [00:27<00:12, 58.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  11% 566M/5.14G [00:26<01:20, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  48% 661M/1.39G [00:27<00:12, 59.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  11% 577M/5.14G [00:26<01:16, 59.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  48% 671M/1.39G [00:27<00:11, 61.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  49% 682M/1.39G [00:28<00:37, 18.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  11% 587M/5.14G [00:28<04:06, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  12% 598M/5.14G [00:28<03:17, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  50% 692M/1.39G [00:29<00:30, 23.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  12% 608M/5.14G [00:28<02:32, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  51% 703M/1.39G [00:29<00:23, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  12% 619M/5.14G [00:28<02:13, 33.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  51% 713M/1.39G [00:29<00:20, 33.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  12% 629M/5.14G [00:28<01:50, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  52% 724M/1.39G [00:29<00:16, 39.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  12% 640M/5.14G [00:29<01:35, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  53% 734M/1.39G [00:29<00:14, 45.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 650M/5.14G [00:29<01:23, 53.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  54% 744M/1.39G [00:29<00:12, 51.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 661M/5.14G [00:29<01:18, 56.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  54% 755M/1.39G [00:29<00:11, 55.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 671M/5.14G [00:29<01:18, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  55% 765M/1.39G [00:30<00:10, 61.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 682M/5.14G [00:29<01:12, 61.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  56% 776M/1.39G [00:30<00:09, 64.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 692M/5.14G [00:29<01:09, 63.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  57% 786M/1.39G [00:30<00:09, 63.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  14% 703M/5.14G [00:29<01:06, 67.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  57% 797M/1.39G [00:30<00:08, 69.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  14% 713M/5.14G [00:30<01:01, 71.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  58% 807M/1.39G [00:30<00:07, 74.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  14% 724M/5.14G [00:30<00:59, 74.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  59% 818M/1.39G [00:30<00:07, 75.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  14% 734M/5.14G [00:30<00:58, 75.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  60% 828M/1.39G [00:30<00:07, 76.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  14% 744M/5.14G [00:30<00:56, 78.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  60% 839M/1.39G [00:31<00:07, 77.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  15% 755M/5.14G [00:30<00:58, 74.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  61% 849M/1.39G [00:31<00:07, 73.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  15% 765M/5.14G [00:30<00:59, 72.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  15% 776M/5.14G [00:30<00:55, 78.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  62% 860M/1.39G [00:31<00:10, 51.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  16% 797M/5.14G [00:31<00:48, 89.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  63% 870M/1.39G [00:31<00:08, 58.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  16% 807M/5.14G [00:31<00:49, 88.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  63% 881M/1.39G [00:31<00:07, 65.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  64% 891M/1.39G [00:31<00:07, 68.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  16% 828M/5.14G [00:31<00:51, 83.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  65% 902M/1.39G [00:32<00:06, 72.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  16% 839M/5.14G [00:31<00:53, 80.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  66% 912M/1.39G [00:32<00:06, 68.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  17% 849M/5.14G [00:31<00:58, 73.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  67% 933M/1.39G [00:32<00:06, 69.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  17% 860M/5.14G [00:32<01:03, 67.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  68% 944M/1.39G [00:32<00:06, 71.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  17% 870M/5.14G [00:32<02:29, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  17% 881M/5.14G [00:33<02:19, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  69% 954M/1.39G [00:33<00:16, 26.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  17% 891M/5.14G [00:33<01:55, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  69% 965M/1.39G [00:33<00:13, 31.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  18% 902M/5.14G [00:33<01:35, 44.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  70% 975M/1.39G [00:34<00:10, 38.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  71% 986M/1.39G [00:34<00:08, 45.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  18% 923M/5.14G [00:33<01:09, 60.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  72% 996M/1.39G [00:34<00:07, 52.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  18% 933M/5.14G [00:33<01:04, 65.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  72% 1.01G/1.39G [00:34<00:06, 60.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  73% 1.02G/1.39G [00:34<00:05, 67.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 954M/5.14G [00:34<00:57, 73.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  74% 1.03G/1.39G [00:34<00:05, 70.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 965M/5.14G [00:34<00:57, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  75% 1.04G/1.39G [00:34<00:04, 72.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 975M/5.14G [00:34<00:55, 75.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  75% 1.05G/1.39G [00:34<00:04, 74.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 986M/5.14G [00:34<00:53, 77.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  76% 1.06G/1.39G [00:35<00:04, 75.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 996M/5.14G [00:34<00:53, 77.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  77% 1.07G/1.39G [00:35<00:04, 77.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  20% 1.01G/5.14G [00:34<00:51, 79.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  20% 1.02G/5.14G [00:34<00:51, 79.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  78% 1.09G/1.39G [00:35<00:03, 89.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  20% 1.03G/5.14G [00:34<00:53, 76.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  79% 1.10G/1.39G [00:35<00:03, 82.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  20% 1.04G/5.14G [00:35<00:50, 81.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  80% 1.11G/1.39G [00:35<00:03, 80.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  81% 1.12G/1.39G [00:35<00:03, 84.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  21% 1.06G/5.14G [00:35<00:45, 89.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  82% 1.13G/1.39G [00:35<00:02, 88.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  21% 1.07G/5.14G [00:35<00:44, 90.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  82% 1.14G/1.39G [00:35<00:02, 91.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  83% 1.15G/1.39G [00:38<00:18, 12.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  21% 1.09G/5.14G [00:38<04:16, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  21% 1.10G/5.14G [00:38<04:00, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  85% 1.17G/1.39G [00:39<00:12, 16.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  86% 1.20G/1.39G [00:39<00:07, 26.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  22% 1.12G/5.14G [00:38<02:35, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  22% 1.14G/5.14G [00:39<01:48, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  88% 1.22G/1.39G [00:39<00:04, 35.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  23% 1.16G/5.14G [00:39<01:24, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  23% 1.17G/5.14G [00:40<02:54, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  89% 1.24G/1.39G [00:41<00:06, 22.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  23% 1.18G/5.14G [00:40<02:26, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  90% 1.25G/1.39G [00:41<00:05, 25.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  23% 1.21G/5.14G [00:41<01:42, 38.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  91% 1.26G/1.39G [00:41<00:04, 29.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  24% 1.23G/5.14G [00:41<01:14, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  92% 1.28G/1.39G [00:41<00:02, 41.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  24% 1.25G/5.14G [00:41<00:59, 65.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  94% 1.30G/1.39G [00:41<00:01, 53.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 1.27G/5.14G [00:41<00:53, 71.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  94% 1.31G/1.39G [00:42<00:01, 56.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 1.29G/5.14G [00:41<00:49, 77.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  96% 1.33G/1.39G [00:42<00:00, 64.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 1.30G/5.14G [00:43<02:18, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  97% 1.34G/1.39G [00:43<00:01, 24.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  26% 1.32G/5.14G [00:43<01:41, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  98% 1.36G/1.39G [00:43<00:00, 35.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  26% 1.33G/5.14G [00:43<01:37, 39.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors:  99% 1.37G/1.39G [00:44<00:00, 36.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  26% 1.34G/5.14G [00:43<01:24, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.fp16.safetensors: 100% 1.39G/1.39G [00:44<00:00, 31.3MB/s]\n",
            "Fetching 23 files:  30% 7/23 [00:47<02:03,  7.73s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  27% 1.36G/5.14G [00:43<01:02, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  27% 1.38G/5.14G [00:44<00:47, 79.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  27% 1.41G/5.14G [00:44<00:38, 97.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  28% 1.43G/5.14G [00:44<00:34, 108MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  28% 1.45G/5.14G [00:45<01:55, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  29% 1.47G/5.14G [00:46<01:27, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  29% 1.49G/5.14G [00:46<01:07, 53.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  29% 1.51G/5.14G [00:47<02:02, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  30% 1.52G/5.14G [00:47<01:47, 33.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  30% 1.54G/5.14G [00:47<01:21, 44.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  30% 1.55G/5.14G [00:48<01:12, 49.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  30% 1.56G/5.14G [00:48<01:04, 55.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  31% 1.57G/5.14G [00:48<00:57, 61.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  31% 1.59G/5.14G [00:48<00:45, 78.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  31% 1.61G/5.14G [00:48<00:36, 95.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  32% 1.64G/5.14G [00:48<00:31, 111MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  32% 1.66G/5.14G [00:48<00:27, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  33% 1.68G/5.14G [00:48<00:24, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  33% 1.70G/5.14G [00:49<00:24, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  33% 1.72G/5.14G [00:49<00:24, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  34% 1.74G/5.14G [00:49<00:24, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  34% 1.76G/5.14G [00:49<00:23, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  35% 1.78G/5.14G [00:49<00:22, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  35% 1.80G/5.14G [00:49<00:21, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  36% 1.82G/5.14G [00:49<00:21, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  36% 1.85G/5.14G [00:50<00:20, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  36% 1.87G/5.14G [00:50<00:20, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  37% 1.89G/5.14G [00:50<00:23, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  37% 1.91G/5.14G [00:50<00:24, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  38% 1.93G/5.14G [00:50<00:23, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  38% 1.95G/5.14G [00:50<00:22, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  38% 1.97G/5.14G [00:53<02:13, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  39% 1.99G/5.14G [00:53<01:38, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  39% 2.01G/5.14G [00:53<01:13, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  40% 2.03G/5.14G [00:53<00:56, 54.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  40% 2.06G/5.14G [00:53<00:44, 68.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  40% 2.08G/5.14G [00:54<00:38, 79.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  41% 2.10G/5.14G [00:54<00:33, 90.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  41% 2.12G/5.14G [00:54<00:29, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  42% 2.14G/5.14G [00:54<00:26, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  42% 2.16G/5.14G [00:54<00:24, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  42% 2.18G/5.14G [00:54<00:23, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  43% 2.20G/5.14G [00:54<00:21, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  43% 2.22G/5.14G [00:55<00:19, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  44% 2.24G/5.14G [00:55<00:19, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  44% 2.26G/5.14G [00:55<00:17, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  45% 2.29G/5.14G [00:55<00:19, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  45% 2.31G/5.14G [00:55<00:21, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  45% 2.33G/5.14G [00:55<00:20, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  46% 2.35G/5.14G [00:55<00:19, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  46% 2.37G/5.14G [00:56<00:19, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  47% 2.39G/5.14G [00:58<01:37, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  47% 2.41G/5.14G [00:58<01:13, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  47% 2.43G/5.14G [00:58<00:56, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  48% 2.45G/5.14G [00:58<00:44, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  48% 2.47G/5.14G [00:58<00:35, 74.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  49% 2.50G/5.14G [00:58<00:29, 90.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  49% 2.52G/5.14G [00:59<00:25, 105MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  49% 2.54G/5.14G [00:59<00:22, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  50% 2.56G/5.14G [00:59<00:21, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  50% 2.58G/5.14G [00:59<00:19, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  51% 2.60G/5.14G [00:59<00:17, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  51% 2.62G/5.14G [00:59<00:16, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  51% 2.64G/5.14G [00:59<00:15, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  52% 2.66G/5.14G [00:59<00:15, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  52% 2.68G/5.14G [01:00<00:15, 154MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  53% 2.71G/5.14G [01:00<00:16, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  53% 2.73G/5.14G [01:00<00:16, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  53% 2.75G/5.14G [01:00<00:16, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  54% 2.77G/5.14G [01:00<00:14, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  54% 2.79G/5.14G [01:00<00:14, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  55% 2.81G/5.14G [01:00<00:14, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  55% 2.83G/5.14G [01:00<00:13, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  56% 2.85G/5.14G [01:01<00:13, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  56% 2.87G/5.14G [01:01<00:13, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  56% 2.89G/5.14G [01:01<00:13, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  57% 2.92G/5.14G [01:01<00:14, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  57% 2.94G/5.14G [01:01<00:14, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  58% 2.96G/5.14G [01:01<00:14, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  58% 2.98G/5.14G [01:01<00:14, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  58% 3.00G/5.14G [01:03<00:50, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  59% 3.02G/5.14G [01:03<00:37, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  59% 3.04G/5.14G [01:03<00:29, 70.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  60% 3.06G/5.14G [01:03<00:26, 79.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  60% 3.08G/5.14G [01:03<00:21, 95.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  60% 3.10G/5.14G [01:03<00:18, 113MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  61% 3.12G/5.14G [01:04<00:15, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  61% 3.15G/5.14G [01:04<00:14, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  62% 3.17G/5.14G [01:04<00:13, 144MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  62% 3.19G/5.14G [01:04<00:12, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  62% 3.21G/5.14G [01:04<00:12, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  63% 3.23G/5.14G [01:04<00:11, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  63% 3.25G/5.14G [01:04<00:10, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  64% 3.27G/5.14G [01:04<00:10, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  64% 3.29G/5.14G [01:04<00:10, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  65% 3.31G/5.14G [01:05<00:10, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  65% 3.33G/5.14G [01:05<00:10, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  65% 3.36G/5.14G [01:05<00:10, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  66% 3.38G/5.14G [01:05<00:10, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  66% 3.40G/5.14G [01:05<00:10, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  67% 3.42G/5.14G [01:05<00:10, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  67% 3.44G/5.14G [01:05<00:09, 175MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  67% 3.46G/5.14G [01:05<00:09, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  68% 3.48G/5.14G [01:06<00:09, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  68% 3.50G/5.14G [01:06<00:08, 184MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  69% 3.52G/5.14G [01:06<00:09, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  69% 3.54G/5.14G [01:06<00:09, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  69% 3.57G/5.14G [01:06<00:09, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  70% 3.59G/5.14G [01:06<00:08, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  70% 3.61G/5.14G [01:06<00:08, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  71% 3.63G/5.14G [01:08<00:32, 45.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  71% 3.65G/5.14G [01:08<00:24, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  71% 3.67G/5.14G [01:08<00:19, 74.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  72% 3.69G/5.14G [01:08<00:17, 84.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  72% 3.71G/5.14G [01:08<00:13, 102MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  73% 3.73G/5.14G [01:08<00:11, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  73% 3.75G/5.14G [01:08<00:10, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  74% 3.77G/5.14G [01:08<00:09, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  74% 3.80G/5.14G [01:09<00:09, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  74% 3.82G/5.14G [01:09<00:08, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  75% 3.84G/5.14G [01:09<00:08, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  75% 3.86G/5.14G [01:09<00:07, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  76% 3.88G/5.14G [01:09<00:07, 175MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  76% 3.90G/5.14G [01:09<00:06, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  76% 3.92G/5.14G [01:09<00:06, 185MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  77% 3.94G/5.14G [01:09<00:06, 187MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  77% 3.96G/5.14G [01:09<00:06, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  78% 3.98G/5.14G [01:10<00:06, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  78% 4.01G/5.14G [01:10<00:06, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  78% 4.03G/5.14G [01:10<00:06, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  79% 4.05G/5.14G [01:10<00:06, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  79% 4.07G/5.14G [01:10<00:06, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  80% 4.09G/5.14G [01:10<00:05, 175MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  80% 4.11G/5.14G [01:10<00:08, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  80% 4.13G/5.14G [01:11<00:07, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  81% 4.15G/5.14G [01:11<00:06, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  81% 4.17G/5.14G [01:11<00:06, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  82% 4.19G/5.14G [01:11<00:06, 156MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  82% 4.22G/5.14G [01:11<00:05, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  82% 4.24G/5.14G [01:11<00:05, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  83% 4.26G/5.14G [01:11<00:05, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  83% 4.28G/5.14G [01:13<00:22, 38.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  84% 4.30G/5.14G [01:13<00:17, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  84% 4.32G/5.14G [01:13<00:13, 61.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  85% 4.34G/5.14G [01:13<00:10, 74.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  85% 4.36G/5.14G [01:13<00:08, 89.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  85% 4.38G/5.14G [01:14<00:07, 105MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  86% 4.40G/5.14G [01:14<00:06, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  86% 4.42G/5.14G [01:14<00:05, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  87% 4.45G/5.14G [01:14<00:04, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  87% 4.47G/5.14G [01:14<00:04, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  87% 4.49G/5.14G [01:14<00:04, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  88% 4.51G/5.14G [01:14<00:04, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  88% 4.53G/5.14G [01:15<00:04, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  89% 4.55G/5.14G [01:15<00:04, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  89% 4.57G/5.14G [01:15<00:03, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  89% 4.59G/5.14G [01:15<00:03, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  90% 4.61G/5.14G [01:15<00:03, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  90% 4.63G/5.14G [01:15<00:03, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  91% 4.66G/5.14G [01:15<00:03, 158MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  91% 4.68G/5.14G [01:15<00:03, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  91% 4.70G/5.14G [01:16<00:02, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  92% 4.72G/5.14G [01:16<00:02, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  92% 4.74G/5.14G [01:16<00:02, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  93% 4.76G/5.14G [01:17<00:10, 36.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  93% 4.78G/5.14G [01:18<00:07, 47.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  94% 4.80G/5.14G [01:18<00:05, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  94% 4.82G/5.14G [01:18<00:06, 51.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  94% 4.84G/5.14G [01:18<00:04, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  95% 4.87G/5.14G [01:18<00:03, 80.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  95% 4.89G/5.14G [01:19<00:02, 89.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  96% 4.91G/5.14G [01:19<00:02, 103MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  96% 4.93G/5.14G [01:19<00:01, 116MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  96% 4.95G/5.14G [01:19<00:01, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  97% 4.97G/5.14G [01:19<00:01, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  97% 4.99G/5.14G [01:19<00:00, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  98% 5.01G/5.14G [01:19<00:00, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  98% 5.03G/5.14G [01:20<00:00, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  98% 5.05G/5.14G [01:20<00:00, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  99% 5.08G/5.14G [01:20<00:00, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  99% 5.10G/5.14G [01:20<00:00, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 5.12G/5.14G [01:20<00:00, 152MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 5.14G/5.14G [01:20<00:00, 63.6MB/s]\n",
            "Fetching 23 files: 100% 23/23 [01:24<00:00,  3.65s/it]\n",
            "The config attributes {'add_watermarker': None} were passed to StableDiffusionXLPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
            "Keyword arguments {'add_watermarker': None} are not expected by StableDiffusionXLPipeline and will be ignored.\n",
            "The config attributes {'force_upcast': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
            "U-Net converted to original U-Net\n",
            "load VAE: /content/vae/sdxl_vae.safetensors\n",
            "additional VAE loaded\n",
            "Enable SDPA for U-Net\n",
            "VAE: Attention.forward has been replaced to sdpa\n",
            "loading tokenizer\n",
            "prepare tokenizers\n",
            "Downloading (…)olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 12.0MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 7.24MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 1.28MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 905/905 [00:00<00:00, 324kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 862k/862k [00:00<00:00, 12.7MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 29.1MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 1.73MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 904/904 [00:00<00:00, 1.90MB/s]\n",
            "set vae_dtype to float32\n",
            "set optimizing: channels last\n",
            "pipeline is ready.\n",
            "iteration 1/1\n",
            "prompt 1/1: andyflinn, man, male, hat, glasses, face, shaven\n",
            "negative prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/\u001b[0m\u001b[1;33msdxl_gen_img.py\u001b[0m:\u001b[94m2527\u001b[0m in \u001b[92m<module>\u001b[0m                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2524 \u001b[0m\u001b[2m│   \u001b[0mparser = setup_parser()                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2525 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2526 \u001b[0m\u001b[2m│   \u001b[0margs = parser.parse_args()                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2527 \u001b[2m│   \u001b[0mmain(args)                                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2528 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/\u001b[0m\u001b[1;33msdxl_gen_img.py\u001b[0m:\u001b[94m2296\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2293 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2294 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mbatch_data.append(b1)                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2295 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(batch_data) == args.batch_size:                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2296 \u001b[2m│   │   │   │   │   \u001b[0mprev_image = process_batch(batch_data, highres_fix)[\u001b[94m0\u001b[0m]                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2297 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mbatch_data.clear()                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2298 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2299 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mglobal_step += \u001b[94m1\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/\u001b[0m\u001b[1;33msdxl_gen_img.py\u001b[0m:\u001b[94m1990\u001b[0m in \u001b[92mprocess_batch\u001b[0m                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1987 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mn.pre_calculation()                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1988 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mpre-calculation... done\u001b[0m\u001b[33m\"\u001b[0m)                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1989 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1990 \u001b[2m│   │   │   \u001b[0mimages = pipe(                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1991 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mprompts,                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1992 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mnegative_prompts,                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1993 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minit_images,                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in \u001b[92mdecorate_context\u001b[0m       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/\u001b[0m\u001b[1;33msdxl_gen_img.py\u001b[0m:\u001b[94m456\u001b[0m in \u001b[92m__call__\u001b[0m                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 453 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m tokenizer, text_encoder \u001b[95min\u001b[0m \u001b[96mzip\u001b[0m(\u001b[96mself\u001b[0m.tokenizers, \u001b[96mself\u001b[0m.text_encoders):          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 454 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_replacer = \u001b[96mself\u001b[0m.get_token_replacer(tokenizer)                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 455 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 456 \u001b[2m│   │   │   \u001b[0mtext_embeddings, text_pool, uncond_embeddings, uncond_pool, _ = get_weighted  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 457 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtokenizer,                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 458 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtext_encoder,                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 459 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mprompt=prompt,                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/\u001b[0m\u001b[1;33msdxl_gen_img.py\u001b[0m:\u001b[94m1064\u001b[0m in \u001b[92mget_weighted_text_embeddings\u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1061 \u001b[0m\u001b[2m│   │   \u001b[0muncond_tokens = torch.tensor(uncond_tokens, dtype=torch.long, device=device)      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1062 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1063 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# get the embeddings\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1064 \u001b[2m│   \u001b[0mtext_embeddings, text_pool = get_unweighted_text_embeddings(                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1065 \u001b[0m\u001b[2m│   │   \u001b[0mtext_encoder,                                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1066 \u001b[0m\u001b[2m│   │   \u001b[0mprompt_tokens,                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1067 \u001b[0m\u001b[2m│   │   \u001b[0mtokenizer.model_max_length,                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/\u001b[0m\u001b[1;33msdxl_gen_img.py\u001b[0m:\u001b[94m978\u001b[0m in \u001b[92mget_unweighted_text_embeddings\u001b[0m                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 975 \u001b[0m\u001b[2m│   │   │   \u001b[0mtext_embeddings.append(text_embedding)                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 976 \u001b[0m\u001b[2m│   │   \u001b[0mtext_embeddings = torch.concat(text_embeddings, axis=\u001b[94m1\u001b[0m)                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 977 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 978 \u001b[2m│   │   \u001b[0menc_out = text_encoder(text_input, output_hidden_states=\u001b[94mTrue\u001b[0m, return_dict=\u001b[94mTrue\u001b[0m)   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 979 \u001b[0m\u001b[2m│   │   \u001b[0mtext_embeddings = enc_out[\u001b[33m\"\u001b[0m\u001b[33mhidden_states\u001b[0m\u001b[33m\"\u001b[0m][-\u001b[94m2\u001b[0m]                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 980 \u001b[0m\u001b[2m│   │   \u001b[0mpool = enc_out.get(\u001b[33m\"\u001b[0m\u001b[33mtext_embeds\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m)  \u001b[2m# text encoder 1 doesn't return this\u001b[0m     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 981 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m text_embeddings, pool                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/\u001b[0m\u001b[1;33mmodeling_clip.py\u001b[0m:\u001b[94m822\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 819 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m```\"\"\"\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 820 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 821 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 822 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.text_model(                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 823 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=input_ids,                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 824 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 825 \u001b[0m\u001b[2m│   │   │   \u001b[0mposition_ids=position_ids,                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/\u001b[0m\u001b[1;33mmodeling_clip.py\u001b[0m:\u001b[94m740\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 737 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[0m                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 738 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask = _expand_mask(attention_mask, hidden_states.dtype)            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 739 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 740 \u001b[2m│   │   \u001b[0mencoder_outputs = \u001b[96mself\u001b[0m.encoder(                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 741 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_embeds=hidden_states,                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 742 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 743 \u001b[0m\u001b[2m│   │   │   \u001b[0mcausal_attention_mask=causal_attention_mask,                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/\u001b[0m\u001b[1;33mmodeling_clip.py\u001b[0m:\u001b[94m654\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 651 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcausal_attention_mask,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 652 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 653 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 654 \u001b[2m│   │   │   │   \u001b[0mlayer_outputs = encoder_layer(                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 655 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 656 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask,                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 657 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcausal_attention_mask,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/clip/\u001b[0m\u001b[1;33mmodeling_clip.py\u001b[0m:\u001b[94m382\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 379 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 380 \u001b[0m\u001b[2m│   │   \u001b[0mresidual = hidden_states                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 381 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 382 \u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.layer_norm1(hidden_states)                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 383 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states, attn_weights = \u001b[96mself\u001b[0m.self_attn(                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 384 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states=hidden_states,                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 385 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mnormalization.py\u001b[0m:\u001b[94m190\u001b[0m in \u001b[92mforward\u001b[0m         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m187 \u001b[0m\u001b[2m│   │   │   \u001b[0minit.zeros_(\u001b[96mself\u001b[0m.bias)                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m188 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m189 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m190 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.layer_norm(                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m191 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.normalized_shape, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias, \u001b[96mself\u001b[0m.eps)                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m193 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mextra_repr\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[96mstr\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m2515\u001b[0m in \u001b[92mlayer_norm\u001b[0m                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2512 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m handle_torch_function(                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2513 \u001b[0m\u001b[2m│   │   │   \u001b[0mlayer_norm, (\u001b[96minput\u001b[0m, weight, bias), \u001b[96minput\u001b[0m, normalized_shape, weight=weight, b  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2514 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2515 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch.layer_norm(\u001b[96minput\u001b[0m, normalized_shape, weight, bias, eps, torch.backends.c  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2516 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2517 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m2518 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mgroup_norm\u001b[0m(                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mRuntimeError: \u001b[0m\u001b[32m\"LayerNormKernelImpl\"\u001b[0m not implemented for \u001b[32m'Half'\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title ## **5.1. Inference**\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "# @markdown ### Model Config\n",
        "network_weights = \"\" #@param {type:'string'}\n",
        "network_mul = 0.7 # @param {type:\"slider\", min:-1, max:1, step:0.05}\n",
        "# @markdown ### Prompt Config\n",
        "prompt = \"andyflinn, man, male, hat, glasses, face, shaven\" #@param {type:'string'}\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type:'string'}\n",
        "output_path = \"/content/drive/MyDrive/Loras/andyflinn/testoutput\" #@param {type:'string'}\n",
        "resolution = \"1024, 1024\" # @param {type: \"string\"}\n",
        "optimization = \"scaled dot-product attention\" # @param [\"xformers\", \"scaled dot-product attention\"]\n",
        "conditional_resolution = \"1024, 1024\" # @param {type: \"string\"}\n",
        "steps = 28 # @param {type: \"number\"}\n",
        "sampler = \"euler_a\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "scale = 7 # @param {type: \"number\"}\n",
        "seed = -1 # @param {type: \"number\"}\n",
        "images_per_prompt = 1 # @param {type: \"number\"}\n",
        "batch_size = 1 # @param {type: \"number\"}\n",
        "clip_skip = 2 # @param {type: \"number\"}\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "separators = [\"*\", \"x\", \",\"]\n",
        "\n",
        "for separator in separators:\n",
        "    if separator in resolution:\n",
        "        width, height = [value.strip() for value in resolution.split(separator)]\n",
        "        original_width, original_height = [value.strip() for value in conditional_resolution.split(separator)]\n",
        "        break\n",
        "\n",
        "network_config = {\n",
        "    \"network_module\": network_module,\n",
        "    \"network_weights\": network_weights,\n",
        "    \"network_show_meta\": True,\n",
        "    \"network_mul\": network_mul,\n",
        "}\n",
        "\n",
        "config = {\n",
        "    \"prompt\": prompt + \" --n \" + negative_prompt,\n",
        "    \"images_per_prompt\": images_per_prompt,\n",
        "    \"outdir\": output_path,\n",
        "    \"W\": width,\n",
        "    \"H\": height,\n",
        "    \"original_width\": original_width,\n",
        "    \"original_height\": original_height,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"vae_batch_size\": 1,\n",
        "    \"no_half_vae\": True,\n",
        "    \"steps\": steps,\n",
        "    \"sampler\": sampler,\n",
        "    \"scale\": scale,\n",
        "    \"ckpt\": model_path,\n",
        "    \"vae\": vae_path,\n",
        "    \"seed\": seed if seed > 0 else None,\n",
        "    \"fp16\": True,\n",
        "    \"sdpa\": True if optimization == \"scaled dot-product attention\" else False,\n",
        "    \"xformers\": True if optimization == \"xformers\" else False,\n",
        "    \"opt_channels_last\": True,\n",
        "    \"clip_skip\": clip_skip,\n",
        "    \"max_embeddings_multiples\": 3,\n",
        "}\n",
        "\n",
        "if network_weights != \"\":\n",
        "    config.update(network_config)\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python sdxl_gen_img.py {args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyIl9BhNXKUq"
      },
      "source": [
        "# **VI. Deployment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p_SHtbFwHVl1",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2a3b89-ffe8-4175-8605-a0d5e5dd716b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading settings from /content/LoRA/config/config_file.toml...\n",
            "/content/LoRA/config/config_file\n",
            "prepare tokenizers\n",
            "update token length: 225\n",
            "Training with captions.\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/\u001b[0m\u001b[1;33msdxl_train_network.py\u001b[0m:\u001b[94m174\u001b[0m in \u001b[92m<module>\u001b[0m                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   \u001b[0margs = train_util.read_config_from_file(args, parser)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   \u001b[0mtrainer = SdxlNetworkTrainer()                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m174 \u001b[2m│   \u001b[0mtrainer.train(args)                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/\u001b[0m\u001b[1;33mtrain_network.py\u001b[0m:\u001b[94m177\u001b[0m in \u001b[92mtrain\u001b[0m                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m}                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m176 \u001b[0m\u001b[2m│   │   │   \u001b[0mblueprint = blueprint_generator.generate(user_config, args, tokenizer=tokeni   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m177 \u001b[2m│   │   │   \u001b[0mtrain_dataset_group = config_util.generate_dataset_group_by_blueprint(bluepr   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# use arbitrary dataset class\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m180 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrain_dataset_group = train_util.load_arbitrary_dataset(args, tokenizer)       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/library/\u001b[0m\u001b[1;33mconfig_util.py\u001b[0m:\u001b[94m426\u001b[0m in \u001b[92mgenerate_dataset_group_by_blueprint\u001b[0m         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m423 \u001b[0m\u001b[2m│     \u001b[0mdataset_klass = FineTuningDataset                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m424 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m425 \u001b[0m\u001b[2m│   \u001b[0msubsets = [subset_klass(**asdict(subset_blueprint.params)) \u001b[94mfor\u001b[0m subset_blueprint \u001b[95min\u001b[0m d   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m426 \u001b[2m│   \u001b[0mdataset = dataset_klass(subsets=subsets, **asdict(dataset_blueprint.params))           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m427 \u001b[0m\u001b[2m│   \u001b[0mdatasets.append(dataset)                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m428 \u001b[0m\u001b[2m  \u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m429 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# print info\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/kohya-trainer/library/\u001b[0m\u001b[1;33mtrain_util.py\u001b[0m:\u001b[94m1477\u001b[0m in \u001b[92m__init__\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1474 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mopen\u001b[0m(subset.metadata_file, \u001b[33m\"\u001b[0m\u001b[33mrt\u001b[0m\u001b[33m\"\u001b[0m, encoding=\u001b[33m\"\u001b[0m\u001b[33mutf-8\u001b[0m\u001b[33m\"\u001b[0m) \u001b[94mas\u001b[0m f:             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1475 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmetadata = json.load(f)                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1476 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1477 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mno metadata / メタデータファイルがありません: \u001b[0m\u001b[33m{\u001b[0msubset  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1478 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1479 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(metadata) < \u001b[94m1\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mignore subset with \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0msubset.metadata_file\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m: no image entries fo\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mValueError: \u001b[0mno metadata \u001b[35m/\u001b[0m メタデータファイルがありません: \u001b[35m/content/LoRA/\u001b[0m\u001b[95mmeta_lat.json\u001b[0m\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m918\u001b[0m in \u001b[92mlaunch_command\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m915 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m defaults \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m defaults.compute_environment == ComputeEnvironment.AMA   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m916 \u001b[0m\u001b[2m│   │   \u001b[0msagemaker_launcher(defaults, args)                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m917 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m918 \u001b[2m│   │   \u001b[0msimple_launcher(args)                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m919 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m920 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m921 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mmain\u001b[0m():                                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m580\u001b[0m in \u001b[92msimple_launcher\u001b[0m     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m577 \u001b[0m\u001b[2m│   \u001b[0mprocess.wait()                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m578 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m process.returncode != \u001b[94m0\u001b[0m:                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m579 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m args.quiet:                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m580 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m581 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m582 \u001b[0m\u001b[2m│   │   │   \u001b[0msys.exit(\u001b[94m1\u001b[0m)                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m583 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mCalledProcessError: \u001b[0mCommand \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m'\u001b[0m\u001b[35m/usr/bin/\u001b[0m\u001b[95mpython3\u001b[0m', \u001b[32m'sdxl_train_network.py'\u001b[0m, \n",
            "\u001b[32m'--\u001b[0m\u001b[32msample_prompts\u001b[0m\u001b[32m=/content/LoRA/config/sample_prompt.toml'\u001b[0m, \n",
            "\u001b[32m'--\u001b[0m\u001b[32mconfig_file\u001b[0m\u001b[32m=/content/LoRA/config/config_file.toml'\u001b[0m, \n",
            "\u001b[32m'--\u001b[0m\u001b[32mwandb_api_key\u001b[0m\u001b[32m=\u001b[0m\u001b[32mffb2849473332017dea8738e3482165e87ecd9c1\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m' returned non-zero exit status \u001b[1;36m1\u001b[0m.\n"
          ]
        }
      ],
      "source": [
        "#@title ## **4.5. Start Training**\n",
        "import os\n",
        "import toml\n",
        "\n",
        "#@markdown Check your config here if you want to edit something:\n",
        "#@markdown - `sample_prompt` : /content/LoRA/config/sample_prompt.toml\n",
        "#@markdown - `config_file` : /content/LoRA/config/config_file.toml\n",
        "\n",
        "\n",
        "#@markdown You can import config from another session if you want.\n",
        "\n",
        "sample_prompt   = \"/content/LoRA/config/sample_prompt.toml\" #@param {type:'string'}\n",
        "config_file     = \"/content/LoRA/config/config_file.toml\" #@param {type:'string'}\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def train(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : \"/content/kohya-trainer/accelerate_config/config.yaml\",\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\"  : sample_prompt if os.path.exists(sample_prompt) else None,\n",
        "    \"config_file\"     : config_file,\n",
        "    \"wandb_api_key\"   : wandb_api_key if wandb_api_key else None\n",
        "}\n",
        "\n",
        "accelerate_args = train(accelerate_conf)\n",
        "train_args = train(train_conf)\n",
        "\n",
        "final_args = f\"accelerate launch {accelerate_args} sdxl_train_network.py {train_args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8YlP0cNQyujy"
      },
      "outputs": [],
      "source": [
        "# @title ## **6.1. Huggingface Hub config**\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "# @markdown Login to Huggingface Hub\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
        "orgs_name = \"\"  # @param{type:\"string\"}\n",
        "# @markdown If your model/dataset repo does not exist, it will automatically create it.\n",
        "model_name = \"sdxl-model\"  # @param{type:\"string\"}\n",
        "dataset_name = \"sdxl-dataset\"  # @param{type:\"string\"}\n",
        "make_private = True  # @param{type:\"boolean\"}\n",
        "\n",
        "def authenticate(write_token):\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "    api = HfApi()\n",
        "    return api.whoami(write_token), api\n",
        "\n",
        "def create_repo(api, user, orgs_name, repo_name, repo_type, make_private=False):\n",
        "    global model_repo\n",
        "    global datasets_repo\n",
        "\n",
        "    if orgs_name == \"\":\n",
        "        repo_id = user[\"name\"] + \"/\" + repo_name.strip()\n",
        "    else:\n",
        "        repo_id = orgs_name + \"/\" + repo_name.strip()\n",
        "\n",
        "    try:\n",
        "        validate_repo_id(repo_id)\n",
        "        api.create_repo(repo_id=repo_id, repo_type=repo_type, private=make_private)\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' didn't exist, creating repo\")\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' exists, skipping create repo\")\n",
        "\n",
        "    if repo_type == \"model\":\n",
        "        model_repo = repo_id\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/{repo_id}\\n\")\n",
        "    else:\n",
        "        datasets_repo = repo_id\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/datasets/{repo_id}\\n\")\n",
        "\n",
        "user, api = authenticate(write_token)\n",
        "\n",
        "if model_name:\n",
        "    create_repo(api, user, orgs_name, model_name, \"model\", make_private)\n",
        "if dataset_name:\n",
        "    create_repo(api, user, orgs_name, dataset_name, \"dataset\", make_private)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8HpOZOglBJTz"
      },
      "outputs": [],
      "source": [
        "# @title ## **6.2. Upload LoRA to Huggingface**\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "\n",
        "%store -r\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# @markdown This will be uploaded to model repo\n",
        "model_path = \"/content/LoRA/output/\"  # @param {type :\"string\"}\n",
        "path_in_repo = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown Now you can save your config file for future use\n",
        "config_path = \"/content/LoRA/config\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown Other Information\n",
        "commit_message = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "    commit_message = f\"feat: upload {project_name} lora model\"\n",
        "\n",
        "def upload_to_hf(model_path, is_folder, is_config):\n",
        "    path_obj = Path(model_path)\n",
        "    trained_model = path_obj.parts[-1]\n",
        "\n",
        "    if path_in_repo:\n",
        "        trained_model = path_in_repo\n",
        "\n",
        "    if is_config:\n",
        "        trained_model = f\"{project_name}_config\"\n",
        "\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/{model_repo}\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    if is_folder:\n",
        "        api.upload_folder(\n",
        "            folder_path=model_path,\n",
        "            path_in_repo=trained_model,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "            ignore_patterns=\".ipynb_checkpoints\",\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/{model_repo}/tree/main\\n\")\n",
        "    else:\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=model_path,\n",
        "            path_in_repo=trained_model,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/{model_repo}/blob/main/{trained_model}\\n\")\n",
        "\n",
        "def upload():\n",
        "    is_model_file = model_path.endswith((\".ckpt\", \".safetensors\", \".pt\"))\n",
        "    upload_to_hf(model_path, not is_model_file, False)\n",
        "\n",
        "    if config_path:\n",
        "        upload_to_hf(config_path, True, True)\n",
        "\n",
        "upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IW-hS9jnmf-E"
      },
      "outputs": [],
      "source": [
        "# @title ## **6.3. Upload Dataset to Huggingface**\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# @markdown This will be compressed to zip and  uploaded to datasets repo, leave it empty if not necessary\n",
        "train_data_path = \"/content/LoRA/train_data\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown `Nerd stuff, only if you want to save training logs`\n",
        "logs_path = \"/content/LoRA/logs\"  # @param {type :\"string\"}\n",
        "\n",
        "tmp_dataset = f\"/content/LoRA/{project_name}_dataset\" if project_name else \"/content/LoRA/tmp_dataset\"\n",
        "tmp_train_data = f\"{tmp_dataset}/train_data\"\n",
        "dataset_zip = f\"{tmp_dataset}.zip\"\n",
        "\n",
        "# @markdown Other Information\n",
        "commit_message = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "    commit_message = f\"feat: upload {project_name} dataset and logs\"\n",
        "\n",
        "os.makedirs(tmp_dataset, exist_ok=True)\n",
        "os.makedirs(tmp_train_data, exist_ok=True)\n",
        "\n",
        "def upload_dataset(dataset_path, is_zip):\n",
        "    path_obj = Path(dataset_path)\n",
        "    dataset_name = path_obj.parts[-1]\n",
        "\n",
        "    print(f\"Uploading {dataset_name} to https://huggingface.co/datasets/{datasets_repo}\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    if is_zip:\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=dataset_path,\n",
        "            path_in_repo=dataset_name,\n",
        "            repo_id=datasets_repo,\n",
        "            repo_type=\"dataset\",\n",
        "            commit_message=commit_message,\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/datasets/{datasets_repo}/blob/main/{dataset_name}\\n\")\n",
        "    else:\n",
        "        api.upload_folder(\n",
        "            folder_path=dataset_path,\n",
        "            path_in_repo=dataset_name,\n",
        "            repo_id=datasets_repo,\n",
        "            repo_type=\"dataset\",\n",
        "            commit_message=commit_message,\n",
        "            ignore_patterns=\".ipynb_checkpoints\",\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/datasets/{datasets_repo}/tree/main/{dataset_name}\\n\")\n",
        "\n",
        "def zip_file(folder_path):\n",
        "    zip_path = f\"{folder_path}.zip\"\n",
        "    with zipfile.ZipFile(zip_path, \"w\") as zip_file:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                zip_file.write(os.path.join(root, file))\n",
        "\n",
        "def move(src_path, dst_path, move_metadata):\n",
        "    metadata_files = [\n",
        "        \"meta_cap.json\",\n",
        "        \"meta_cap_dd.json\",\n",
        "        \"meta_lat.json\",\n",
        "        \"meta_clean.json\",\n",
        "        \"meta_final.json\",\n",
        "    ]\n",
        "\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "    if move_metadata:\n",
        "        parent_meta_path = os.path.dirname(src_path)\n",
        "\n",
        "        for filename in os.listdir(parent_meta_path):\n",
        "            file_path = os.path.join(parent_meta_path, filename)\n",
        "            if filename in metadata_files:\n",
        "                shutil.move(file_path, dst_path)\n",
        "\n",
        "def upload():\n",
        "    if train_data_path:\n",
        "        move(train_data_path, tmp_train_data, False)\n",
        "        zip_file(tmp_dataset)\n",
        "        upload_dataset(dataset_zip, True)\n",
        "        os.remove(dataset_zip)\n",
        "    if logs_path:\n",
        "        upload_dataset(logs_path, False)\n",
        "\n",
        "upload()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}