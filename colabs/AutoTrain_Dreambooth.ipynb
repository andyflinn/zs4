{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andyflinn/zs4/blob/master/colabs/AutoTrain_Dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JvMRbVLEJlZT",
        "outputId": "36ac0d38-5fce-48b3-fc79-3905e2965780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m> \u001b[1mINFO    Installing latest transformers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest transformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest peft@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest peft\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest diffusers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest diffusers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest trl@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest trl\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@title ðŸ¤— AutoTrain DreamBooth\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload images to a folder named `images/`\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can also select sd2/2.1 or sd1.5\n",
        "#@markdown - update prompt and remember it. choose keywords that don't usually appear in dictionaries\n",
        "#@markdown - add huggingface information (token and repo_id) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt\n",
        "!autotrain setup --colab > setup_logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgYxlvLKqgok",
        "outputId": "da75ae5b-ca8b-40be-95fc-b7759f219d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'andyflinn' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'andyflinn' # @param {type: \"string\"}\n",
        "image_folder = \"/content/drive/MyDrive/images/\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "repo_id = \"andyflinn/andyflinn\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_fp16 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "train_text_encoder = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "gradient_checkpointing = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"IMAGE_FOLDER\"] = image_folder\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"REPO_ID\"] = repo_id\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"USE_FP16\"] = str(use_fp16)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"GRADIENT_CHECKPOINTING\"] = str(gradient_checkpointing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g3cd_ED_yXXt",
        "outputId": "aaea726f-c8c7-488a-c578-67149175c201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "> \u001b[1mINFO    Namespace(version=False, model='stabilityai/stable-diffusion-xl-base-1.0', revision=None, tokenizer=None, image_path='/content/drive/MyDrive/images/', class_image_path=None, prompt='andyflinn', class_prompt=None, num_class_images=100, class_labels_conditioning=None, prior_preservation=None, prior_loss_weight=1.0, project_name='andyflinn', seed=42, resolution=1024, center_crop=None, train_text_encoder=None, batch_size=1, sample_batch_size=4, epochs=1, num_steps=500, checkpointing_steps=100000, resume_from_checkpoint=None, gradient_accumulation=4, gradient_checkpointing=True, lr=0.0001, scale_lr=None, scheduler='constant', warmup_steps=0, num_cycles=1, lr_power=1.0, dataloader_num_workers=0, use_8bit_adam=True, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, allow_tf32=None, prior_generation_precision=None, local_rank=-1, xformers=True, pre_compute_text_embeddings=None, tokenizer_max_length=None, text_encoder_use_attention_mask=None, rank=4, xl=None, fp16=True, bf16=None, token='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', repo_id='andyflinn/andyflinn', push_to_hub=True, validation_prompt=None, num_validation_images=4, validation_epochs=50, checkpoints_total_limit=None, validation_images=None, logging=None, username=None, func=<function run_dreambooth_command_factory at 0x780cfcc5f640>)\u001b[0m\n",
            "> \u001b[1mINFO    Running DreamBooth Training\u001b[0m\n",
            "> \u001b[33m\u001b[1mWARNING Parameters supplied but not used: version, func\u001b[0m\n",
            "Downloading (â€¦)okenizer_config.json: 100% 737/737 [00:00<00:00, 3.56MB/s]\n",
            "Downloading (â€¦)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 6.08MB/s]\n",
            "Downloading (â€¦)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 4.29MB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 2.06MB/s]\n",
            "Downloading (â€¦)okenizer_config.json: 100% 725/725 [00:00<00:00, 3.25MB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.34MB/s]\n",
            "Downloading (â€¦)_encoder/config.json: 100% 565/565 [00:00<00:00, 2.39MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading (â€¦)ncoder_2/config.json: 100% 575/575 [00:00<00:00, 2.29MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading model.safetensors: 100% 492M/492M [00:04<00:00, 101MB/s] \n",
            "Downloading model.safetensors: 100% 2.78G/2.78G [00:36<00:00, 76.0MB/s]\n",
            "Downloading (â€¦)main/vae/config.json: 100% 642/642 [00:00<00:00, 3.22MB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 335M/335M [00:04<00:00, 82.4MB/s]\n",
            "Downloading (â€¦)ain/unet/config.json: 100% 1.68k/1.68k [00:00<00:00, 8.93MB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 10.3G/10.3G [02:23<00:00, 71.4MB/s]\n",
            "{'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (â€¦)cheduler_config.json: 100% 479/479 [00:00<00:00, 2.37MB/s]\n",
            "{'thresholding', 'variance_type', 'dynamic_thresholding_ratio', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "> \u001b[1mINFO    Enabling xformers\u001b[0m\n",
            "> \u001b[1mINFO    Enabling gradient checkpointing.\u001b[0m\n",
            "> \u001b[1mINFO    Computing text embeddings for prompt: andyflinn\u001b[0m\n",
            "> \u001b[1mINFO    ***** Running training *****\u001b[0m\n",
            "> \u001b[1mINFO      Num examples = 60\u001b[0m\n",
            "> \u001b[1mINFO      Num batches each epoch = 60\u001b[0m\n",
            "> \u001b[1mINFO      Num Epochs = 34\u001b[0m\n",
            "> \u001b[1mINFO      Instantaneous batch size per device = 1\u001b[0m\n",
            "> \u001b[1mINFO      Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "> \u001b[1mINFO      Gradient Accumulation steps = 4\u001b[0m\n",
            "> \u001b[1mINFO      Total optimization steps = 500\u001b[0m\n",
            "> \u001b[1mINFO      Training config = {'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'revision': None, 'tokenizer': None, 'image_path': '/content/drive/MyDrive/images/', 'class_image_path': None, 'prompt': 'andyflinn', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'andyflinn', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 34, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'gradient_checkpointing': True, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': True, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'fp16': True, 'bf16': False, 'token': '*****', 'repo_id': 'andyflinn/andyflinn', 'push_to_hub': True, 'username': None, 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "Steps:   0% 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/diffusers/models/attention_processor.py:1468: FutureWarning: `LoRAAttnProcessor2_0` is deprecated and will be removed in version 0.26.0. Make sure use AttnProcessor2_0 instead by settingLoRA layers to `self.{to_q,to_k,to_v,to_out[0]}.lora_layer` respectively. This will be done automatically when using `LoraLoaderMixin.load_lora_weights`\n",
            "  deprecate(\n",
            "Steps: 100% 500/500 [2:01:16<00:00, 14.53s/it, loss=0.136, lr=0.0001]Model weights saved in andyflinn/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 500/500 [2:01:16<00:00, 14.55s/it, loss=0.136, lr=0.0001]\n",
            "> \u001b[31m\u001b[1mERROR   train has failed due to an exception:\u001b[0m\n",
            "> \u001b[31m\u001b[1mERROR   Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 261, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 1021, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/api/models/andyflinn/andyflinn/preupload/main\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/utils.py\", line 280, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/trainers/dreambooth/__main__.py\", line 291, in train\n",
            "    trainer.push_to_hub()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/trainers/dreambooth/trainer.py\", line 454, in push_to_hub\n",
            "    upload_folder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 849, in _inner\n",
            "    return fn(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 3748, in upload_folder\n",
            "    commit_info = self.create_commit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 849, in _inner\n",
            "    return fn(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 2914, in create_commit\n",
            "    upload_modes = fetch_upload_modes(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_commit_api.py\", line 482, in fetch_upload_modes\n",
            "    hf_raise_for_status(resp)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 303, in hf_raise_for_status\n",
            "    raise HfHubHTTPError(str(e), response=response) from e\n",
            "huggingface_hub.utils._errors.HfHubHTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/api/models/andyflinn/andyflinn/preupload/main (Request ID: Root=1-653b7f0c-664cd6852272529f591d82ed;7b319b68-f914-44d7-ad38-a18e30759ddd)\n",
            "\n",
            "Forbidden: you must use a write token to upload to a repository.\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path \"${IMAGE_FOLDER}\" \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "$( [[ \"$USE_FP16\" == \"True\" ]] && echo \"--fp16\" ) \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN} --repo-id ${REPO_ID}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LvIS7-7PcLT"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "# this is the inference code that you can use after you have trained your model\n",
        "# Unhide code below and change prj_path to your repo or local path (e.g. my_dreambooth_project)\n",
        "#\n",
        "#\n",
        "#\n",
        "# from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "# import torch\n",
        "\n",
        "# prj_path = \"username/repo_name\"\n",
        "# model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "# pipe = DiffusionPipeline.from_pretrained(\n",
        "#     model,\n",
        "#     torch_dtype=torch.float16,\n",
        "# )\n",
        "# pipe.to(\"cuda\")\n",
        "# pipe.load_lora_weights(prj_path, weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "# refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "#     \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "#     torch_dtype=torch.float16,\n",
        "# )\n",
        "# refiner.to(\"cuda\")\n",
        "\n",
        "# prompt = \"photo of a sks dog in a bucket\"\n",
        "\n",
        "# seed = 42\n",
        "# generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "# image = pipe(prompt=prompt, generator=generator).images[0]\n",
        "# image = refiner(prompt=prompt, generator=generator, image=image).images[0]\n",
        "# image.save(f\"generated_image.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}